{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 2: Simple Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Part 1: Single Hidden Layer with Sigmoid Activation Function\n",
    "\n",
    "<!-- insert png of nn1 -->\n",
    "![image](nn1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #1: Illustrate the Matrices Associated with the Neural Network  \n",
    "\n",
    " \n",
    "$X = \n",
    "\\begin{bmatrix}\n",
    "x_1\\\\\n",
    "x_2\\\\\n",
    "x_3\n",
    "\\end{bmatrix}$\n",
    "\n",
    "$W1 = \n",
    "\\begin{bmatrix}\n",
    "w_{11} & w_{21} & w_{31}\\\\\n",
    "w_{12} & w_{22} & w_{32}\\\\\n",
    "w_{13} & w_{23} & w_{33}\\\\\n",
    "w_{14} & w_{24} & w_{34}\\\\\n",
    "\\end{bmatrix}$\n",
    "\n",
    "$H = \n",
    "\\begin{bmatrix}\n",
    "h_1\\\\\n",
    "h_2\\\\ \n",
    "h_3\\\\\n",
    "h_4\\\\\n",
    "\\end{bmatrix}$\n",
    "\n",
    "$W2 =\n",
    "\\begin{bmatrix}\n",
    "w_{11} & w_{21} & w_{31} & w_{41}\\\\\n",
    "\\end{bmatrix}$\n",
    "\n",
    "$B = \n",
    "\\begin{bmatrix}\n",
    "b_1\\\\\n",
    "b_2\\\\\n",
    "b_3\\\\\n",
    "b_4\\\\\n",
    "\\end{bmatrix}$\n",
    "\n",
    "$C \\in \\mathbb{R}$ (c is a scalar)\n",
    "\n",
    "$Z1 = W1 * X + B = \n",
    "\\begin{bmatrix}\n",
    "z_1\\\\\n",
    "z_2\\\\\n",
    "z_3\\\\\n",
    "z_4\\\\\n",
    "\\end{bmatrix}$\n",
    "\n",
    "$\\sigma (z) = \\frac{1}{1+e^{-z}}$\n",
    "\n",
    "$H = \\sigma(Z1)$ \n",
    "\n",
    "$Z2 = W2 * H + C$ (scalar)\n",
    "\n",
    "$\\hat{y} = \\sigma(Z2)$ (scalar)\n",
    "\n",
    "$y \\in \\mathbb{R}$ (scalar)\n",
    "\n",
    "$\\hat{y} - y \\in \\mathbb{R} $ (scalar)\n",
    "\n",
    "Assuming binary cross entropy:  \n",
    "\n",
    "$L = -y\\log(\\hat{y}) - (1-y)\\log(1-\\hat{y})$ (scalar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #2: Use Python to Code the Feed Forward portion of this Neural Network\n",
    "a-c. Create a dataset and read it in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data is: \n",
      "    experience  skill  athleticism label\n",
      "0           5      8            5  good\n",
      "1           4      4            3  good\n",
      "2           2      2            4   bad\n",
      "3           0      2            3   bad\n",
      "4           5      6            5  good\n",
      "5           1      0            0   bad\n",
      "\n",
      "X is: \n",
      " [[1.   1.   1.  ]\n",
      " [0.6  0.8  0.5 ]\n",
      " [0.8  0.4  0.25]\n",
      " [0.6  0.   0.25]\n",
      " [1.   1.   0.75]\n",
      " [0.   0.2  0.  ]]\n",
      "\n",
      "Y is: \n",
      " [[0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "#2a-c: Create and read in dataa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def read_data(path):\n",
    "    return pd.read_csv(path)\n",
    "\n",
    "def clean_data(df):\n",
    "   \n",
    "    nrows = df.shape[0]\n",
    "    ncols = df.shape[1]\n",
    "   \n",
    "    x = np.empty((nrows,ncols-1))\n",
    "    y = np.empty((nrows,1))\n",
    "\n",
    "    # separate labels\n",
    "    if 'LABEL' in df.columns:\n",
    "        y = np.array(df['LABEL'])\n",
    "        x = np.array(df[df.columns.difference(['LABEL'])])\n",
    "    elif 'label' in df.columns:\n",
    "        y = np.array(df['label'])\n",
    "        x = np.array(df[df.columns.difference(['label'])])\n",
    "    else:\n",
    "        raise Exception('There is no column with the title label in the data')\n",
    "    \n",
    "    y = convert_labels(y)\n",
    "    y = y.reshape(-1, 1) \n",
    "    x = normalize(x)\n",
    "    return x, y\n",
    "\n",
    "def convert_labels(y):\n",
    "    y_values = set(y)\n",
    "    y_value_0 = list(y_values)[0]\n",
    "    y_value_1 = list(y_values)[1]\n",
    "\n",
    "    y[y == y_value_0] = 0\n",
    "    y[y == y_value_1] = 1\n",
    "    return y\n",
    "\n",
    "def normalize(x):\n",
    "    xrows = x.shape[0]\n",
    "    xcols = x.shape[1]\n",
    "    xnorm = np.empty((xrows, xcols))\n",
    "    for j, column in enumerate(x.T):\n",
    "        max = column.max()\n",
    "        min = column.min()\n",
    "        for i, item in enumerate(column):\n",
    "            xnorm[i,j] = (item - min)/(max - min)\n",
    "    return xnorm\n",
    "\n",
    "df = read_data('A2_Data_ILG.csv')\n",
    "x, y = clean_data(df)\n",
    "\n",
    "print('The data is: \\n', df)\n",
    "print('\\nX is: \\n', x)\n",
    "print('\\nY is: \\n', y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 6 is different from 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 44\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss\n\u001b[1;32m     43\u001b[0m nn1 \u001b[39m=\u001b[39m NeuralNetwork(\u001b[39m0.1\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[0;32m---> 44\u001b[0m y_hat \u001b[39m=\u001b[39m nn1\u001b[39m.\u001b[39;49mfeed_forward(x)\n\u001b[1;32m     45\u001b[0m loss \u001b[39m=\u001b[39m nn1\u001b[39m.\u001b[39mcalculate_loss(y)\n\u001b[1;32m     47\u001b[0m \u001b[39m# Print out X, y, W1, B, Z1, H1, W2, Z2, C, y^, y^-y, and L.\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[7], line 33\u001b[0m, in \u001b[0;36mNeuralNetwork.feed_forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfeed_forward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> 33\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mz1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mw1 \u001b[39m@\u001b[39;49m x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mb\n\u001b[1;32m     34\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mh \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msigmoid(\u001b[39m-\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mz1)\n\u001b[1;32m     35\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mz2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mh \u001b[39m@\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mw2 \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mc\n",
      "\u001b[0;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 6 is different from 3)"
     ]
    }
   ],
   "source": [
    "#2d: Code a sigmoid function and the derivative\n",
    "def sigmoid(z):\n",
    "        return 1/(1+np.exp(-z))\n",
    "\n",
    "def sigmoid_derivative(z):\n",
    "    return sigmoid(z) * (1-sigmoid(z))\n",
    "\n",
    "#2e: Code the loss function\n",
    "def mse(y, y_hat):\n",
    "    return np.square(y - y_hat).mean()\n",
    "\n",
    "#2: Code the feedforward function\n",
    "import numpy as np\n",
    "\n",
    "class NeuralNetwork:\n",
    "\n",
    "    def __init__(self, learning_rate, epochs):\n",
    "        # shape parameters\n",
    "        # hidden_layers = 1\n",
    "        hidden_layer_size = 4\n",
    "        output_layer_size = 1\n",
    "        input_layer_size = 3\n",
    "\n",
    "        # initialize\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.w1 = np.ones((hidden_layer_size, input_layer_size))\n",
    "        self.b = np.zeros((hidden_layer_size, 1))\n",
    "        self.w2 = 2 * np.ones((hidden_layer_size, output_layer_size))\n",
    "        self.c = -1 * np.ones((1, output_layer_size))\n",
    "\n",
    "    def feed_forward(self, x):\n",
    "        self.z1 = self.w1 @ x + self.b\n",
    "        self.h = self.sigmoid(-self.z1)\n",
    "        self.z2 = self.h @ self.w2 + self.c\n",
    "        self.y_hat = self.sigmoid(self.z2)\n",
    "        return self.y_hat\n",
    "   \n",
    "    def calculate_loss(self, y):\n",
    "        self.loss = (y @ np.log(self.y_hat) + (1-y) @ np.log(1-self.y_hat))\n",
    "        return self.loss\n",
    "\n",
    "nn1 = NeuralNetwork(0.1, 1)\n",
    "y_hat = nn1.feed_forward(x)\n",
    "loss = nn1.calculate_loss(y)\n",
    "\n",
    "# Print out X, y, W1, B, Z1, H1, W2, Z2, C, y^, y^-y, and L.\n",
    "print('X is: \\n', x)\n",
    "print('\\ny is: \\n', y)\n",
    "print('\\nW1 is: \\n', nn1.w1)\n",
    "print('\\nB is: \\n', nn1.b)\n",
    "print('\\nZ1 is: \\n', nn1.z1)\n",
    "print('\\nH is: \\n', nn1.h)\n",
    "print('\\nW2 is: \\n', nn1.w2)\n",
    "print('\\nZ2 is: \\n', nn1.z2)\n",
    "print('\\nC is: \\n', nn1.c)\n",
    "print('\\ny^ is: \\n', nn1.y_hat)\n",
    "print('\\ny^-y is: \\n', nn1.y_hat - y)\n",
    "print('\\nL is: \\n', nn1.loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def update_weights(self, y):\n",
    "        print('updating weights')\n",
    "\n",
    "    def train(self, x, y):\n",
    "        self.initialize_weights()\n",
    "        print('training the model.')\n",
    "        for _ in range(self.epochs):\n",
    "            self.feed_forward()\n",
    "            self.calculate_loss(y)\n",
    "            self.update_weights(y)\n",
    "            return "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
