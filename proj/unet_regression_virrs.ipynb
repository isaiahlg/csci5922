{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "esIMGVxhDI0f"
      },
      "outputs": [],
      "source": [
        "#@title Copyright 2020 Google LLC. { display-mode: \"form\" }\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aV1xZ1CPi3Nw"
      },
      "source": [
        "<table class=\"ee-notebook-buttons\" align=\"left\"><td>\n",
        "<a target=\"_blank\"  href=\"http://colab.research.google.com/github/google/earthengine-community/blob/master/guides/linked/UNET_regression_demo.ipynb\">\n",
        "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" /> Run in Google Colab</a>\n",
        "</td><td>\n",
        "<a target=\"_blank\"  href=\"https://github.com/google/earthengine-community/blob/master/guides/linked/UNET_regression_demo.ipynb\"><img width=32px src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" /> View source on GitHub</a></td></table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# To Do\n",
        "- [x] Figure out how to extract image patches for model training\n",
        "- [x] Extract Sentinel 2 and Planet Data\n",
        "- [x] Figure out which type of model to use\n",
        "- [x] Figure out how to run one of these scripts  \n",
        "xxx\n",
        "- [x] Get the notebook running locally with the tfrecords saved locally  \n",
        "- [x] Train a model with small subset of the data  \n",
        "- [x] Get the model prediction and inference code to run with local files\n",
        "- [x] Get a simple version of the model trained  \n",
        "xxx\n",
        "- [ ] Substitute Landsat 8 with Sentinel 2  \n",
        "- [ ] Substitute NLCD with nightlights  \n",
        "- [ ] Retrain a simple model with the new data\n",
        "xxx\n",
        "- [ ] Set up a python env on the lab computer\n",
        "- [ ] Set up SSH on the lab computer\n",
        "- [ ] Scale up the model  \n",
        "- [ ] Determine hyperparameters  \n",
        "- [ ] Run on lab computer  \n",
        "xxx\n",
        "- [ ] Run again with Landsat  \n",
        "- [ ] Consider running again with Planet  \n",
        "- [ ] Consider running again with a ViT  \n",
        "xxx\n",
        "- [ ] Look wealth instead of nightlights data  \n",
        "- [ ] Look at effect of dataset size on model performance  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SHAc5qbiR8l"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "This is an Earth Engine <> TensorFlow notebook.  Suppose you want to predict a continuous output (regression) from a stack of continuous inputs.  In this example, the output is VIIRS Day/Night Band from [VIIRS](https://developers.google.com/earth-engine/datasets/catalog/NOAA_VIIRS_DNB_MONTHLY_V1_VCMSLCFG) and the input is a Landsat 8 composite.  The model is a [fully convolutional neural network (FCNN)](https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Long_Fully_Convolutional_Networks_2015_CVPR_paper.pdf), specifically [U-net](https://arxiv.org/abs/1505.04597). In this notebook, we:\n",
        "\n",
        "1.   Export train/test patches from Earth Engine, suitable for training an FCNN model.\n",
        "2.   Preprocess the data. \n",
        "3.   Train and validating an FCNN model.\n",
        "4.   Maki predictions with the trained model and import them to Earth Engine."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MJ4kW1pEhwP"
      },
      "source": [
        "# Setup software libraries\n",
        "\n",
        "Authenticate and import as necessary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "neIa46CpciXq"
      },
      "outputs": [],
      "source": [
        "# Cloud authentication when running in Colab\n",
        "# Fix error: https://stackoverflow.com/questions/75666380/attributeerror-module-ipython-utils-traitlets-has-no-attribute-unicode\n",
        "# from google.auth import auth\n",
        "# import google\n",
        "# auth.authenticate_user()\n",
        "\n",
        "# Local authenticate when running locally\n",
        "# ensure you have the Google Cloud SDK installed and configured\n",
        "!gcloud auth login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jat01FEoUMqg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "To authorize access needed by Earth Engine, open the following URL in a web browser and follow the instructions. If the web browser does not start automatically, please manually browse the URL below.\n",
            "\n",
            "    https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=VBDWaZyveuameEkbc4k3xzDKiuBbdPI05m9o0a9ft_4&tc=6ri-N5A9Lp3Kp8wiPpj7ENYVaIed0P0atQXQkFhNwYI&cc=ZnPM_omaoGVSyLxRekUESSqJzyfZPjCqPHpmu8l_KEA\n",
            "\n",
            "The authorization workflow will generate a code, which you should paste in the box below.\n",
            "\n",
            "Successfully saved authorization token.\n"
          ]
        }
      ],
      "source": [
        "# Import, authenticate and initialize the Earth Engine library.\n",
        "import ee\n",
        "ee.Authenticate()\n",
        "ee.Initialize()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8RnZzcYhcpsQ"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-12-08 09:23:44.959163: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "/Users/ilyonsg/miniconda3/envs/tfgee/lib/python3.9/site-packages/scipy/__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.2\n",
            "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.11.0\n"
          ]
        }
      ],
      "source": [
        "# Tensorflow setup.\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "n1hFdpBQfyhN"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.15.0\n"
          ]
        }
      ],
      "source": [
        "# Folium setup.\n",
        "import folium\n",
        "print(folium.__version__)\n",
        "# TODO substitude with geemap"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iT8ycmzClYwf"
      },
      "source": [
        "# Variables\n",
        "\n",
        "Declare the variables that will be in use throughout the notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKs6HuxOzjMl"
      },
      "source": [
        "## Specify your Cloud Storage Bucket\n",
        "You must have write access to a bucket to run this demo!  To run it read-only, use the demo bucket below, but note that writes to this bucket will not work."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "obDDH1eDzsch"
      },
      "outputs": [],
      "source": [
        "# INSERT YOUR BUCKET HERE:\n",
        "BUCKET = 'csci5922-proj'\n",
        "# BUCKET = '/Users/ilyonsg/Documents/courses/csci5922/proj/data'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmfKLl9XcnGJ"
      },
      "source": [
        "## Set other global variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "psz7wJKalaoj"
      },
      "outputs": [],
      "source": [
        "# Specify names locations for outputs in Cloud Storage.\n",
        "FOLDER = 'unet-viirs'\n",
        "TRAINING_BASE = 'training_patches'\n",
        "EVAL_BASE = 'eval_patches'\n",
        "DATA_PATH = '/Users/ilyonsg/Documents/courses/csci5922/proj/data/unet-viirs/'\n",
        "\n",
        "# Specify inputs (Landsat bands) to the model and the response variable.\n",
        "opticalBands = ['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7']\n",
        "thermalBands = ['B10', 'B11']\n",
        "BANDS = opticalBands + thermalBands\n",
        "RESPONSE = 'avg_rad' ##### \n",
        "FEATURES = BANDS + [RESPONSE]\n",
        "\n",
        "# Specify the size and shape of patches expected by the model.\n",
        "KERNEL_SIZE = 256\n",
        "KERNEL_SHAPE = [KERNEL_SIZE, KERNEL_SIZE]\n",
        "COLUMNS = [\n",
        "  tf.io.FixedLenFeature(shape=KERNEL_SHAPE, dtype=tf.float32) for k in FEATURES\n",
        "]\n",
        "FEATURES_DICT = dict(zip(FEATURES, COLUMNS))\n",
        "\n",
        "# Sizes of the training and evaluation datasets.\n",
        "TRAIN_SIZE = 1800 # down 10X\n",
        "EVAL_SIZE = 800 # down 10X\n",
        "\n",
        "# Specify model training parameters.\n",
        "BATCH_SIZE = 18\n",
        "EPOCHS = 10\n",
        "BUFFER_SIZE = 2000\n",
        "OPTIMIZER = 'SGD'\n",
        "LOSS = 'MeanSquaredError'\n",
        "METRICS = ['RootMeanSquaredError']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgoDc7Hilfc4"
      },
      "source": [
        "# Create and Stack Input + Target Imagery\n",
        "\n",
        "Gather and setup the imagery to use for inputs (predictors).  This is a three-year, cloud-free, Landsat 8 composite.  Display it in the notebook for a sanity check."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "-IlgXu-vcUEY"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><span style=\"color:#565656\">Make this Notebook Trusted to load map: File -> Trust Notebook</span><iframe srcdoc=\"&lt;!DOCTYPE html&gt;\n",
              "&lt;html&gt;\n",
              "&lt;head&gt;\n",
              "    \n",
              "    &lt;meta http-equiv=&quot;content-type&quot; content=&quot;text/html; charset=UTF-8&quot; /&gt;\n",
              "    \n",
              "        &lt;script&gt;\n",
              "            L_NO_TOUCH = false;\n",
              "            L_DISABLE_3D = false;\n",
              "        &lt;/script&gt;\n",
              "    \n",
              "    &lt;style&gt;html, body {width: 100%;height: 100%;margin: 0;padding: 0;}&lt;/style&gt;\n",
              "    &lt;style&gt;#map {position:absolute;top:0;bottom:0;right:0;left:0;}&lt;/style&gt;\n",
              "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;script src=&quot;https://code.jquery.com/jquery-3.7.1.min.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/js/bootstrap.bundle.min.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/css/bootstrap.min.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap.min.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.2.0/css/all.min.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/gh/python-visualization/folium/folium/templates/leaflet.awesome.rotate.min.css&quot;/&gt;\n",
              "    \n",
              "            &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width,\n",
              "                initial-scale=1.0, maximum-scale=1.0, user-scalable=no&quot; /&gt;\n",
              "            &lt;style&gt;\n",
              "                #map_823c1a34b613f598350241dee1a6d013 {\n",
              "                    position: relative;\n",
              "                    width: 100.0%;\n",
              "                    height: 100.0%;\n",
              "                    left: 0.0%;\n",
              "                    top: 0.0%;\n",
              "                }\n",
              "                .leaflet-container { font-size: 1rem; }\n",
              "            &lt;/style&gt;\n",
              "        \n",
              "&lt;/head&gt;\n",
              "&lt;body&gt;\n",
              "    \n",
              "    \n",
              "            &lt;div class=&quot;folium-map&quot; id=&quot;map_823c1a34b613f598350241dee1a6d013&quot; &gt;&lt;/div&gt;\n",
              "        \n",
              "&lt;/body&gt;\n",
              "&lt;script&gt;\n",
              "    \n",
              "    \n",
              "            var map_823c1a34b613f598350241dee1a6d013 = L.map(\n",
              "                &quot;map_823c1a34b613f598350241dee1a6d013&quot;,\n",
              "                {\n",
              "                    center: [-1.0, 37.0],\n",
              "                    crs: L.CRS.EPSG3857,\n",
              "                    zoom: 8,\n",
              "                    zoomControl: true,\n",
              "                    preferCanvas: false,\n",
              "                }\n",
              "            );\n",
              "\n",
              "            \n",
              "\n",
              "        \n",
              "    \n",
              "            var tile_layer_d81dd084e4709c34348e2aecd46c32f9 = L.tileLayer(\n",
              "                &quot;https://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png&quot;,\n",
              "                {&quot;attribution&quot;: &quot;Data by \\u0026copy; \\u003ca target=\\&quot;_blank\\&quot; href=\\&quot;http://openstreetmap.org\\&quot;\\u003eOpenStreetMap\\u003c/a\\u003e, under \\u003ca target=\\&quot;_blank\\&quot; href=\\&quot;http://www.openstreetmap.org/copyright\\&quot;\\u003eODbL\\u003c/a\\u003e.&quot;, &quot;detectRetina&quot;: false, &quot;maxNativeZoom&quot;: 18, &quot;maxZoom&quot;: 18, &quot;minZoom&quot;: 0, &quot;noWrap&quot;: false, &quot;opacity&quot;: 1, &quot;subdomains&quot;: &quot;abc&quot;, &quot;tms&quot;: false}\n",
              "            );\n",
              "        \n",
              "    \n",
              "                tile_layer_d81dd084e4709c34348e2aecd46c32f9.addTo(map_823c1a34b613f598350241dee1a6d013);\n",
              "    \n",
              "            var tile_layer_8ff6e2470ceb832675c7997a13a79445 = L.tileLayer(\n",
              "                &quot;https://earthengine.googleapis.com/v1/projects/earthengine-legacy/maps/84a03442b49148829c3bb1a6cf655500-ea36c028ef82e7736160268c20fd77cc/tiles/{z}/{x}/{y}&quot;,\n",
              "                {&quot;attribution&quot;: &quot;Map Data \\u0026copy; \\u003ca href=\\&quot;https://earthengine.google.com/\\&quot;\\u003eGoogle Earth Engine\\u003c/a\\u003e&quot;, &quot;detectRetina&quot;: false, &quot;maxNativeZoom&quot;: 18, &quot;maxZoom&quot;: 18, &quot;minZoom&quot;: 0, &quot;noWrap&quot;: false, &quot;opacity&quot;: 1, &quot;subdomains&quot;: &quot;abc&quot;, &quot;tms&quot;: false}\n",
              "            );\n",
              "        \n",
              "    \n",
              "                tile_layer_8ff6e2470ceb832675c7997a13a79445.addTo(map_823c1a34b613f598350241dee1a6d013);\n",
              "    \n",
              "            var tile_layer_a37a39acfdb4a79c425d69e6f1f7cc67 = L.tileLayer(\n",
              "                &quot;https://earthengine.googleapis.com/v1/projects/earthengine-legacy/maps/1772702befa7ba2f8ec672852fba6f15-dcde2134a83382ff65f1bdbc566fef55/tiles/{z}/{x}/{y}&quot;,\n",
              "                {&quot;attribution&quot;: &quot;Map Data \\u0026copy; \\u003ca href=\\&quot;https://earthengine.google.com/\\&quot;\\u003eGoogle Earth Engine\\u003c/a\\u003e&quot;, &quot;detectRetina&quot;: false, &quot;maxNativeZoom&quot;: 18, &quot;maxZoom&quot;: 18, &quot;minZoom&quot;: 0, &quot;noWrap&quot;: false, &quot;opacity&quot;: 1, &quot;subdomains&quot;: &quot;abc&quot;, &quot;tms&quot;: false}\n",
              "            );\n",
              "        \n",
              "    \n",
              "                tile_layer_a37a39acfdb4a79c425d69e6f1f7cc67.addTo(map_823c1a34b613f598350241dee1a6d013);\n",
              "    \n",
              "            var layer_control_27a68c18db79e5ad8a74b1995e00ede3_layers = {\n",
              "                base_layers : {\n",
              "                    &quot;openstreetmap&quot; : tile_layer_d81dd084e4709c34348e2aecd46c32f9,\n",
              "                },\n",
              "                overlays :  {\n",
              "                    &quot;median composite&quot; : tile_layer_8ff6e2470ceb832675c7997a13a79445,\n",
              "                    &quot;thermal&quot; : tile_layer_a37a39acfdb4a79c425d69e6f1f7cc67,\n",
              "                },\n",
              "            };\n",
              "            let layer_control_27a68c18db79e5ad8a74b1995e00ede3 = L.control.layers(\n",
              "                layer_control_27a68c18db79e5ad8a74b1995e00ede3_layers.base_layers,\n",
              "                layer_control_27a68c18db79e5ad8a74b1995e00ede3_layers.overlays,\n",
              "                {&quot;autoZIndex&quot;: true, &quot;collapsed&quot;: true, &quot;position&quot;: &quot;topright&quot;}\n",
              "            ).addTo(map_823c1a34b613f598350241dee1a6d013);\n",
              "\n",
              "        \n",
              "&lt;/script&gt;\n",
              "&lt;/html&gt;\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
            ],
            "text/plain": [
              "<folium.folium.Map at 0x1697f1c40>"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Use Landsat 8 surface reflectance data.\n",
        "l8sr = ee.ImageCollection('LANDSAT/LC08/C01/T1_SR')\n",
        "\n",
        "# Cloud masking function.\n",
        "def maskL8sr(image):\n",
        "  cloudShadowBitMask = ee.Number(2).pow(3).int()\n",
        "  cloudsBitMask = ee.Number(2).pow(5).int()\n",
        "  qa = image.select('pixel_qa')\n",
        "  mask1 = qa.bitwiseAnd(cloudShadowBitMask).eq(0).And(\n",
        "    qa.bitwiseAnd(cloudsBitMask).eq(0))\n",
        "  mask2 = image.mask().reduce('min')\n",
        "  mask3 = image.select(opticalBands).gt(0).And(\n",
        "          image.select(opticalBands).lt(10000)).reduce('min')\n",
        "  mask = mask1.And(mask2).And(mask3)\n",
        "  return image.select(opticalBands).divide(10000).addBands(\n",
        "          image.select(thermalBands).divide(10).clamp(273.15, 373.15)\n",
        "            .subtract(273.15).divide(100)).updateMask(mask)\n",
        "\n",
        "# The image input data is a cloud-masked median composite.\n",
        "image = l8sr.filterDate('2021-01-01', '2022-12-31').map(maskL8sr).median()\n",
        "\n",
        "# Use folium to visualize the imagery.\n",
        "mapid = image.getMapId({'bands': ['B4', 'B3', 'B2'], 'min': 0, 'max': 0.3})\n",
        "map = folium.Map(location=[-1, 37], zoom_start=8)\n",
        "folium.TileLayer(\n",
        "    tiles=mapid['tile_fetcher'].url_format,\n",
        "    attr='Map Data &copy; <a href=\"https://earthengine.google.com/\">Google Earth Engine</a>',\n",
        "    overlay=True,\n",
        "    name='median composite',\n",
        "  ).add_to(map)\n",
        "\n",
        "mapid = image.getMapId({'bands': ['B10'], 'min': 0, 'max': 0.5})\n",
        "folium.TileLayer(\n",
        "    tiles=mapid['tile_fetcher'].url_format,\n",
        "    attr='Map Data &copy; <a href=\"https://earthengine.google.com/\">Google Earth Engine</a>',\n",
        "    overlay=True,\n",
        "    name='thermal',\n",
        "  ).add_to(map)\n",
        "map.add_child(folium.LayerControl())\n",
        "map"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHznnctkJsZJ"
      },
      "source": [
        "Prepare the response (what we want to predict).  This is nighttime brightness (in nanoWatts/sr/cm^2) from the VIIRS dataset.  Display to check."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "e0wHDyxVirec"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><span style=\"color:#565656\">Make this Notebook Trusted to load map: File -> Trust Notebook</span><iframe srcdoc=\"&lt;!DOCTYPE html&gt;\n",
              "&lt;html&gt;\n",
              "&lt;head&gt;\n",
              "    \n",
              "    &lt;meta http-equiv=&quot;content-type&quot; content=&quot;text/html; charset=UTF-8&quot; /&gt;\n",
              "    \n",
              "        &lt;script&gt;\n",
              "            L_NO_TOUCH = false;\n",
              "            L_DISABLE_3D = false;\n",
              "        &lt;/script&gt;\n",
              "    \n",
              "    &lt;style&gt;html, body {width: 100%;height: 100%;margin: 0;padding: 0;}&lt;/style&gt;\n",
              "    &lt;style&gt;#map {position:absolute;top:0;bottom:0;right:0;left:0;}&lt;/style&gt;\n",
              "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;script src=&quot;https://code.jquery.com/jquery-3.7.1.min.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/js/bootstrap.bundle.min.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/css/bootstrap.min.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap.min.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.2.0/css/all.min.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/gh/python-visualization/folium/folium/templates/leaflet.awesome.rotate.min.css&quot;/&gt;\n",
              "    \n",
              "            &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width,\n",
              "                initial-scale=1.0, maximum-scale=1.0, user-scalable=no&quot; /&gt;\n",
              "            &lt;style&gt;\n",
              "                #map_1437b19faa3c9f179eb318a2e3acf4d2 {\n",
              "                    position: relative;\n",
              "                    width: 100.0%;\n",
              "                    height: 100.0%;\n",
              "                    left: 0.0%;\n",
              "                    top: 0.0%;\n",
              "                }\n",
              "                .leaflet-container { font-size: 1rem; }\n",
              "            &lt;/style&gt;\n",
              "        \n",
              "&lt;/head&gt;\n",
              "&lt;body&gt;\n",
              "    \n",
              "    \n",
              "            &lt;div class=&quot;folium-map&quot; id=&quot;map_1437b19faa3c9f179eb318a2e3acf4d2&quot; &gt;&lt;/div&gt;\n",
              "        \n",
              "&lt;/body&gt;\n",
              "&lt;script&gt;\n",
              "    \n",
              "    \n",
              "            var map_1437b19faa3c9f179eb318a2e3acf4d2 = L.map(\n",
              "                &quot;map_1437b19faa3c9f179eb318a2e3acf4d2&quot;,\n",
              "                {\n",
              "                    center: [-1.0, 37.0],\n",
              "                    crs: L.CRS.EPSG3857,\n",
              "                    zoom: 8,\n",
              "                    zoomControl: true,\n",
              "                    preferCanvas: false,\n",
              "                }\n",
              "            );\n",
              "\n",
              "            \n",
              "\n",
              "        \n",
              "    \n",
              "            var tile_layer_a80d465357b2076f7ce6cfeaa00a04cb = L.tileLayer(\n",
              "                &quot;https://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png&quot;,\n",
              "                {&quot;attribution&quot;: &quot;Data by \\u0026copy; \\u003ca target=\\&quot;_blank\\&quot; href=\\&quot;http://openstreetmap.org\\&quot;\\u003eOpenStreetMap\\u003c/a\\u003e, under \\u003ca target=\\&quot;_blank\\&quot; href=\\&quot;http://www.openstreetmap.org/copyright\\&quot;\\u003eODbL\\u003c/a\\u003e.&quot;, &quot;detectRetina&quot;: false, &quot;maxNativeZoom&quot;: 18, &quot;maxZoom&quot;: 18, &quot;minZoom&quot;: 0, &quot;noWrap&quot;: false, &quot;opacity&quot;: 1, &quot;subdomains&quot;: &quot;abc&quot;, &quot;tms&quot;: false}\n",
              "            );\n",
              "        \n",
              "    \n",
              "                tile_layer_a80d465357b2076f7ce6cfeaa00a04cb.addTo(map_1437b19faa3c9f179eb318a2e3acf4d2);\n",
              "    \n",
              "            var tile_layer_d3bc5880f0908a91469653fa4b3b98d6 = L.tileLayer(\n",
              "                &quot;https://earthengine.googleapis.com/v1/projects/earthengine-legacy/maps/bd9b48d31ea9e35cfa1baf290b946b8b-2e76535a4c6f597ada19e9f911227be1/tiles/{z}/{x}/{y}&quot;,\n",
              "                {&quot;attribution&quot;: &quot;Map Data \\u0026copy; \\u003ca href=\\&quot;https://earthengine.google.com/\\&quot;\\u003eGoogle Earth Engine\\u003c/a\\u003e&quot;, &quot;detectRetina&quot;: false, &quot;maxNativeZoom&quot;: 18, &quot;maxZoom&quot;: 18, &quot;minZoom&quot;: 0, &quot;noWrap&quot;: false, &quot;opacity&quot;: 1, &quot;subdomains&quot;: &quot;abc&quot;, &quot;tms&quot;: false}\n",
              "            );\n",
              "        \n",
              "    \n",
              "                tile_layer_d3bc5880f0908a91469653fa4b3b98d6.addTo(map_1437b19faa3c9f179eb318a2e3acf4d2);\n",
              "    \n",
              "            var layer_control_8f75a7bbb05eb4a3d2792cd759e2e143_layers = {\n",
              "                base_layers : {\n",
              "                    &quot;openstreetmap&quot; : tile_layer_a80d465357b2076f7ce6cfeaa00a04cb,\n",
              "                },\n",
              "                overlays :  {\n",
              "                    &quot;viirs dnb&quot; : tile_layer_d3bc5880f0908a91469653fa4b3b98d6,\n",
              "                },\n",
              "            };\n",
              "            let layer_control_8f75a7bbb05eb4a3d2792cd759e2e143 = L.control.layers(\n",
              "                layer_control_8f75a7bbb05eb4a3d2792cd759e2e143_layers.base_layers,\n",
              "                layer_control_8f75a7bbb05eb4a3d2792cd759e2e143_layers.overlays,\n",
              "                {&quot;autoZIndex&quot;: true, &quot;collapsed&quot;: true, &quot;position&quot;: &quot;topright&quot;}\n",
              "            ).addTo(map_1437b19faa3c9f179eb318a2e3acf4d2);\n",
              "\n",
              "        \n",
              "&lt;/script&gt;\n",
              "&lt;/html&gt;\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
            ],
            "text/plain": [
              "<folium.folium.Map at 0x16989d3a0>"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "viirs = ee.ImageCollection('NOAA/VIIRS/DNB/MONTHLY_V1/VCMSLCFG').select('avg_rad').filterDate('2021-01-01', '2022-12-31').median()\n",
        "viirs = viirs.divide(60).float() # normalize to 0-1 range\n",
        "\n",
        "mapid = viirs.getMapId({'min': 0, 'max': 0.05}) # normally max 1.0\n",
        "map = folium.Map(location=[-1, 37], zoom_start=8)\n",
        "folium.TileLayer(\n",
        "    tiles=mapid['tile_fetcher'].url_format,\n",
        "    attr='Map Data &copy; <a href=\"https://earthengine.google.com/\">Google Earth Engine</a>',\n",
        "    overlay=True,\n",
        "    name='viirs dnb',\n",
        "  ).add_to(map)\n",
        "map.add_child(folium.LayerControl())\n",
        "# map"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTS7_ZzPDhhg"
      },
      "source": [
        "Stack the 2D images (Landsat composite and VIIRS DNB image) to create a single image from which samples can be taken.  Convert the image into an array image in which each pixel stores 256x256 patches of pixels for each band.  This is a key step that bears emphasis: to export training patches, convert a multi-band image to [an array image](https://developers.google.com/earth-engine/arrays_array_images#array-images) using [`neighborhoodToArray()`](https://developers.google.com/earth-engine/api_docs#eeimageneighborhoodtoarray), then sample the image at points."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "eGHYsdAOipa4"
      },
      "outputs": [],
      "source": [
        "featureStack = ee.Image.cat([\n",
        "  image.select(BANDS),\n",
        "  viirs.select(RESPONSE)\n",
        "]).float()\n",
        "\n",
        "list = ee.List.repeat(1, KERNEL_SIZE)\n",
        "lists = ee.List.repeat(list, KERNEL_SIZE)\n",
        "kernel = ee.Kernel.fixed(KERNEL_SIZE, KERNEL_SIZE, lists)\n",
        "\n",
        "arrays = featureStack.neighborhoodToArray(kernel)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4djSxBRG2el"
      },
      "source": [
        "# Define Training and Evaluation Areas\n",
        "Use some pre-made geometries to sample the stack in strategic locations.  Specifically, these are hand-made polygons in which to take the 256x256 samples.  Display the sampling polygons on a map, red for training polygons, blue for evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "ure_WaD0itQY"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'type': 'FeatureCollection', 'columns': {'system:index': 'String'}, 'version': 1701715229285060.0, 'id': 'projects/master-thesis-ilg/assets/trainingPolys', 'properties': {'system:asset_size': 9536}, 'features': [{'type': 'Feature', 'geometry': {'type': 'Polygon', 'coordinates': [[[-105.54634549357169, 39.59859906384958], [-104.74983664401647, 39.59859905890037], [-104.74983664401647, 39.95743841491241], [-105.54634549357169, 39.9574383867131], [-105.54634549357169, 39.59859906384958]]]}, 'id': '00000000000000000000', 'properties': {}}, {'type': 'Feature', 'geometry': {'type': 'Polygon', 'coordinates': [[[-107.2574660979202, 34.8986595709669], [-106.46645040923522, 34.89865960553435], [-106.46645040923522, 35.38378805974467], [-107.2574660979202, 35.38378804637503], [-107.2574660979202, 34.8986595709669]]]}, 'id': '00000000000000000001', 'properties': {}}, {'type': 'Feature', 'geometry': {'type': 'Polygon', 'coordinates': [[[-88.0533645328941, 41.5037437972272], [-87.17445823287098, 41.5037437862478], [-87.17445823287098, 42.0934331851314], [-88.0533645328941, 42.093433189280475], [-88.0533645328941, 41.5037437972272]]]}, 'id': '00000000000000000002', 'properties': {}}, {'type': 'Feature', 'geometry': {'type': 'Polygon', 'coordinates': [[[-75.3971145180029, 39.837330165641056], [-74.86977072924941, 39.83733018199916], [-74.86977072924941, 40.15715071284395], [-75.3971145180029, 40.157150717556284], [-75.3971145180029, 39.837330165641056]]]}, 'id': '00000000000000000003', 'properties': {}}, {'type': 'Feature', 'geometry': {'type': 'Polygon', 'coordinates': [[[-97.08412624011643, 32.633939728049185], [-96.51283714994906, 32.63393970760335], [-96.51283714994906, 32.92951152871112], [-97.08412624011643, 32.929511501338574], [-97.08412624011643, 32.633939728049185]]]}, 'id': '00000000000000000004', 'properties': {}}, {'type': 'Feature', 'geometry': {'type': 'Polygon', 'coordinates': [[[-122.96791529858066, 37.48717280826288], [-121.86928250427833, 37.48717281249815], [-121.86928250427833, 38.14676172115597], [-122.96791529858066, 38.146761782647786], [-122.96791529858066, 37.48717280826288]]]}, 'id': '00000000000000000005', 'properties': {}}, {'type': 'Feature', 'geometry': {'type': 'Polygon', 'coordinates': [[[-118.57338405623892, 33.81030374912534], [-117.51869655888028, 33.81030377321624], [-117.51869655888028, 34.356248171567174], [-118.57338405623892, 34.35624819021128], [-118.57338405623892, 33.81030374912534]]]}, 'id': '00000000000000000006', 'properties': {}}, {'type': 'Feature', 'geometry': {'type': 'Polygon', 'coordinates': [[[-112.4649855686242, 33.00325085603018], [-111.58607936641765, 33.00325083561803], [-111.58607936641765, 33.59094271386093], [-112.4649855686242, 33.59094270908891], [-112.4649855686242, 33.00325085603018]]]}, 'id': '00000000000000000007', 'properties': {}}, {'type': 'Feature', 'geometry': {'type': 'Polygon', 'coordinates': [[[-93.43666527349423, 44.88243943025742], [-92.99721217316963, 44.88243942965946], [-92.99721215588436, 45.19297403183069], [-93.43666528225069, 45.19297401364163], [-93.43666527349423, 44.88243943025742]]]}, 'id': '00000000000000000008', 'properties': {}}]}\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><span style=\"color:#565656\">Make this Notebook Trusted to load map: File -> Trust Notebook</span><iframe srcdoc=\"&lt;!DOCTYPE html&gt;\n",
              "&lt;html&gt;\n",
              "&lt;head&gt;\n",
              "    \n",
              "    &lt;meta http-equiv=&quot;content-type&quot; content=&quot;text/html; charset=UTF-8&quot; /&gt;\n",
              "    \n",
              "        &lt;script&gt;\n",
              "            L_NO_TOUCH = false;\n",
              "            L_DISABLE_3D = false;\n",
              "        &lt;/script&gt;\n",
              "    \n",
              "    &lt;style&gt;html, body {width: 100%;height: 100%;margin: 0;padding: 0;}&lt;/style&gt;\n",
              "    &lt;style&gt;#map {position:absolute;top:0;bottom:0;right:0;left:0;}&lt;/style&gt;\n",
              "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;script src=&quot;https://code.jquery.com/jquery-3.7.1.min.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/js/bootstrap.bundle.min.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/css/bootstrap.min.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap.min.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.2.0/css/all.min.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/gh/python-visualization/folium/folium/templates/leaflet.awesome.rotate.min.css&quot;/&gt;\n",
              "    \n",
              "            &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width,\n",
              "                initial-scale=1.0, maximum-scale=1.0, user-scalable=no&quot; /&gt;\n",
              "            &lt;style&gt;\n",
              "                #map_463e1a5df7d9198f03e2e87fa48e3e14 {\n",
              "                    position: relative;\n",
              "                    width: 100.0%;\n",
              "                    height: 100.0%;\n",
              "                    left: 0.0%;\n",
              "                    top: 0.0%;\n",
              "                }\n",
              "                .leaflet-container { font-size: 1rem; }\n",
              "            &lt;/style&gt;\n",
              "        \n",
              "&lt;/head&gt;\n",
              "&lt;body&gt;\n",
              "    \n",
              "    \n",
              "            &lt;div class=&quot;folium-map&quot; id=&quot;map_463e1a5df7d9198f03e2e87fa48e3e14&quot; &gt;&lt;/div&gt;\n",
              "        \n",
              "&lt;/body&gt;\n",
              "&lt;script&gt;\n",
              "    \n",
              "    \n",
              "            var map_463e1a5df7d9198f03e2e87fa48e3e14 = L.map(\n",
              "                &quot;map_463e1a5df7d9198f03e2e87fa48e3e14&quot;,\n",
              "                {\n",
              "                    center: [38.0, -100.0],\n",
              "                    crs: L.CRS.EPSG3857,\n",
              "                    zoom: 5,\n",
              "                    zoomControl: true,\n",
              "                    preferCanvas: false,\n",
              "                }\n",
              "            );\n",
              "\n",
              "            \n",
              "\n",
              "        \n",
              "    \n",
              "            var tile_layer_4531de0803aa24674cb6e843367467f9 = L.tileLayer(\n",
              "                &quot;https://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png&quot;,\n",
              "                {&quot;attribution&quot;: &quot;Data by \\u0026copy; \\u003ca target=\\&quot;_blank\\&quot; href=\\&quot;http://openstreetmap.org\\&quot;\\u003eOpenStreetMap\\u003c/a\\u003e, under \\u003ca target=\\&quot;_blank\\&quot; href=\\&quot;http://www.openstreetmap.org/copyright\\&quot;\\u003eODbL\\u003c/a\\u003e.&quot;, &quot;detectRetina&quot;: false, &quot;maxNativeZoom&quot;: 18, &quot;maxZoom&quot;: 18, &quot;minZoom&quot;: 0, &quot;noWrap&quot;: false, &quot;opacity&quot;: 1, &quot;subdomains&quot;: &quot;abc&quot;, &quot;tms&quot;: false}\n",
              "            );\n",
              "        \n",
              "    \n",
              "                tile_layer_4531de0803aa24674cb6e843367467f9.addTo(map_463e1a5df7d9198f03e2e87fa48e3e14);\n",
              "    \n",
              "            var tile_layer_1a85fb32d0eb7f8702af3c1177599cad = L.tileLayer(\n",
              "                &quot;https://earthengine.googleapis.com/v1/projects/earthengine-legacy/maps/054d6c4a9aef837ef9dd1aa2b82a2af7-88a8266420f03ddff6b7c32cc57f1ff8/tiles/{z}/{x}/{y}&quot;,\n",
              "                {&quot;attribution&quot;: &quot;Map Data \\u0026copy; \\u003ca href=\\&quot;https://earthengine.google.com/\\&quot;\\u003eGoogle Earth Engine\\u003c/a\\u003e&quot;, &quot;detectRetina&quot;: false, &quot;maxNativeZoom&quot;: 18, &quot;maxZoom&quot;: 18, &quot;minZoom&quot;: 0, &quot;noWrap&quot;: false, &quot;opacity&quot;: 1, &quot;subdomains&quot;: &quot;abc&quot;, &quot;tms&quot;: false}\n",
              "            );\n",
              "        \n",
              "    \n",
              "                tile_layer_1a85fb32d0eb7f8702af3c1177599cad.addTo(map_463e1a5df7d9198f03e2e87fa48e3e14);\n",
              "    \n",
              "            var layer_control_f546174bbcee637016500730e56bcbbf_layers = {\n",
              "                base_layers : {\n",
              "                    &quot;openstreetmap&quot; : tile_layer_4531de0803aa24674cb6e843367467f9,\n",
              "                },\n",
              "                overlays :  {\n",
              "                    &quot;training polygons&quot; : tile_layer_1a85fb32d0eb7f8702af3c1177599cad,\n",
              "                },\n",
              "            };\n",
              "            let layer_control_f546174bbcee637016500730e56bcbbf = L.control.layers(\n",
              "                layer_control_f546174bbcee637016500730e56bcbbf_layers.base_layers,\n",
              "                layer_control_f546174bbcee637016500730e56bcbbf_layers.overlays,\n",
              "                {&quot;autoZIndex&quot;: true, &quot;collapsed&quot;: true, &quot;position&quot;: &quot;topright&quot;}\n",
              "            ).addTo(map_463e1a5df7d9198f03e2e87fa48e3e14);\n",
              "\n",
              "        \n",
              "&lt;/script&gt;\n",
              "&lt;/html&gt;\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
            ],
            "text/plain": [
              "<folium.folium.Map at 0x169b509d0>"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# trainingPolys = ee.FeatureCollection('projects/google/DemoTrainingGeometries')\n",
        "# evalPolys = ee.FeatureCollection('projects/google/DemoEvalGeometries')\n",
        "trainingPolys = ee.FeatureCollection('projects/master-thesis-ilg/assets/trainingPolys')\n",
        "evalPolys = ee.FeatureCollection('projects/master-thesis-ilg/assets/evalPolys')\n",
        "print(trainingPolys.getInfo())\n",
        "\n",
        "polyImage = ee.Image(0).byte().paint(trainingPolys, 1).paint(evalPolys, 2)\n",
        "polyImage = polyImage.updateMask(polyImage)\n",
        "\n",
        "mapid = polyImage.getMapId({'min': 1, 'max': 2, 'palette': ['red', 'blue']})\n",
        "map = folium.Map(location=[38., -100.], zoom_start=5)\n",
        "folium.TileLayer(\n",
        "    tiles=mapid['tile_fetcher'].url_format,\n",
        "    attr='Map Data &copy; <a href=\"https://earthengine.google.com/\">Google Earth Engine</a>',\n",
        "    overlay=True,\n",
        "    name='training polygons',\n",
        "  ).add_to(map)\n",
        "map.add_child(folium.LayerControl())\n",
        "map"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZV890gPHeZqz"
      },
      "source": [
        "# Sampling\n",
        "\n",
        "The mapped data look reasonable so take a sample from each polygon and merge the results into a single export.  The key step is sampling the array image at points, to get all the pixels in a 256x256 neighborhood at each point.  It's worth noting that to build the training and testing data for the FCNN, you export a single TFRecord file that contains patches of pixel values in each record.  You do NOT need to export each training/testing patch to a different image.  Since each record potentially contains a lot of data (especially with big patches or many input bands), some manual sharding of the computation is necessary to avoid the `computed value too large` error.  Specifically, the following code takes multiple (smaller) samples within each geometry, merging the results to get a single export."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "cellView": "both",
        "id": "FyRpvwENxE-A"
      },
      "outputs": [],
      "source": [
        "# Convert the feature collections to lists for iteration.\n",
        "trainingPolysList = trainingPolys.toList(trainingPolys.size())\n",
        "evalPolysList = evalPolys.toList(evalPolys.size())\n",
        "\n",
        "# These numbers determined experimentally.\n",
        "n = 20 # Number of shards in each polygon. # formerly 200\n",
        "N = 200 # Total sample size in each polygon. # formerly 2000\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Export Data to Cloud Storage\n",
        "This can be modified to export to local storage, just adjust the file paths."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 unet-viirs csci5922-proj training_patches_g0\n",
            "1 unet-viirs csci5922-proj training_patches_g1\n",
            "2 unet-viirs csci5922-proj training_patches_g2\n",
            "3 unet-viirs csci5922-proj training_patches_g3\n",
            "4 unet-viirs csci5922-proj training_patches_g4\n",
            "5 unet-viirs csci5922-proj training_patches_g5\n",
            "6 unet-viirs csci5922-proj training_patches_g6\n",
            "7 unet-viirs csci5922-proj training_patches_g7\n",
            "8 unet-viirs csci5922-proj training_patches_g8\n",
            "Training imagery tasks submitted! Check on the Tasks in GEE for their status (https://code.earthengine.google.com/tasks).\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Export all the training data (in many pieces), with one task\n",
        "# per geometry.\n",
        "for g in range(trainingPolys.size().getInfo()):\n",
        "  geomSample = ee.FeatureCollection([])\n",
        "  for i in range(n):\n",
        "    sample = arrays.sample(\n",
        "      region = ee.Feature(trainingPolysList.get(g)).geometry(),\n",
        "      scale = 30,\n",
        "      numPixels = N / n, # Size of the shard.\n",
        "      seed = i,\n",
        "      tileScale = 8\n",
        "    )\n",
        "    geomSample = geomSample.merge(sample)\n",
        "  \n",
        "  desc = TRAINING_BASE + '_g' + str(g)\n",
        "  print(g, FOLDER, BUCKET, desc)\n",
        "  \n",
        "  task = ee.batch.Export.table.toCloudStorage(\n",
        "    collection = geomSample,\n",
        "    description = desc,\n",
        "    bucket = BUCKET,\n",
        "    fileNamePrefix = FOLDER + '/' + desc,\n",
        "    fileFormat = 'TFRecord',\n",
        "    selectors = BANDS + [RESPONSE]\n",
        "  )\n",
        "  task.start()\n",
        "print('Training imagery tasks submitted! Check on the Tasks in GEE for their status (https://code.earthengine.google.com/tasks).')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 unet-viirs csci5922-proj eval_patches_g0\n",
            "1 unet-viirs csci5922-proj eval_patches_g1\n",
            "2 unet-viirs csci5922-proj eval_patches_g2\n",
            "3 unet-viirs csci5922-proj eval_patches_g3\n",
            "Eval imagery tasks submitted! Check on the Tasks in GEE for their status (https://code.earthengine.google.com/tasks).\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Export all the evaluation data.\n",
        "for g in range(evalPolys.size().getInfo()):\n",
        "  geomSample = ee.FeatureCollection([])\n",
        "  for i in range(n):\n",
        "    sample = arrays.sample(\n",
        "      region = ee.Feature(evalPolysList.get(g)).geometry(),\n",
        "      scale = 30,\n",
        "      numPixels = N / n,\n",
        "      seed = i,\n",
        "      tileScale = 8\n",
        "    )\n",
        "    geomSample = geomSample.merge(sample)\n",
        "\n",
        "  desc = EVAL_BASE + '_g' + str(g)\n",
        "  print(g, FOLDER, BUCKET, desc)\n",
        "  \n",
        "  task = ee.batch.Export.table.toCloudStorage(\n",
        "    collection = geomSample,\n",
        "    description = desc,\n",
        "    bucket = BUCKET,\n",
        "    fileNamePrefix = FOLDER + '/' + desc,\n",
        "    fileFormat = 'TFRecord',\n",
        "    selectors = BANDS + [RESPONSE]\n",
        "  )\n",
        "  task.start()\n",
        "print('Eval imagery tasks submitted! Check on the Tasks in GEE for their status (https://code.earthengine.google.com/tasks).')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Copy Files from Cloud Storage to Local Storage\n",
        "This is necessary to run the model locally. Run these here, or in the terminal to free up the Python kernel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "If you experience problems with multiprocessing on MacOS, they might be related to https://bugs.python.org/issue33725. You can disable multiprocessing by editing your .boto config or by adding the following flag to your command: `-o \"GSUtil:parallel_process_count=1\"`. Note that multithreading is still available even if you disable multiprocessing.\n",
            "\n",
            "Copying gs://csci5922-proj/unet-viirs/eval_patches_g0.tfrecord.gz...\n",
            "Copying gs://csci5922-proj/unet-viirs/eval_patches_g1.tfrecord.gz...            \n",
            "Copying gs://csci5922-proj/unet-viirs/eval_patches_g2.tfrecord.gz...            \n",
            "Copying gs://csci5922-proj/unet-viirs/eval_patches_g3.tfrecord.gz...            \n",
            "Copying gs://csci5922-proj/unet-viirs/training_patches_g0.tfrecord.gz...        \n",
            "Copying gs://csci5922-proj/unet-viirs/training_patches_g1.tfrecord.gz...        \n",
            "Copying gs://csci5922-proj/unet-viirs/training_patches_g2.tfrecord.gz...        \n",
            "Copying gs://csci5922-proj/unet-viirs/training_patches_g3.tfrecord.gz...        \n",
            "Copying gs://csci5922-proj/unet-viirs/training_patches_g4.tfrecord.gz...        \n",
            "Copying gs://csci5922-proj/unet-viirs/training_patches_g5.tfrecord.gz...        \n",
            "Copying gs://csci5922-proj/unet-viirs/training_patches_g6.tfrecord.gz...        \n",
            "Copying gs://csci5922-proj/unet-viirs/training_patches_g7.tfrecord.gz...        \n",
            "Copying gs://csci5922-proj/unet-viirs/training_patches_g8.tfrecord.gz...\n",
            "\\ [13/14 files][  2.3 GiB/  2.3 GiB]  99% Done  18.0 MiB/s ETA 00:00:00         \r"
          ]
        }
      ],
      "source": [
        "\n",
        "# Copy from your bucket to local path (note -r is for recursive call)\n",
        "\n",
        "# entire folder\n",
        "# !gsutil cp -m -r gs://csci5922-proj/unet-demo /Users/ilyonsg/Documents/courses/csci5922/proj/data\n",
        "# !gsutil -m cp -r gs://csci5922-proj/unet /Users/ilyonsg/Documents/courses/csci5922/proj/data\n",
        "!gsutil -m cp -r gs://csci5922-proj/unet-viirs /Users/ilyonsg/Documents/courses/csci5922/proj/data\n",
        "\n",
        "# single file\n",
        "# !gsutil cp gs://csci5922-proj/unet/training_patches_g2.tfrecord.gz /Users/ilyonsg/Documents/courses/csci5922/proj/data/unet/training_patches_g2.tfrecord.gz\n",
        "\n",
        "# multiple files per gcs\n",
        "# gsutil -m cp \\\n",
        "#   \"gs://csci5922-proj/unet/eval_patches_g0.tfrecord.gz\" \\\n",
        "#   \"gs://csci5922-proj/unet/eval_patches_g1.tfrecord.gz\" \\\n",
        "#   \"gs://csci5922-proj/unet/eval_patches_g2.tfrecord.gz\" \\\n",
        "#   \"gs://csci5922-proj/unet/eval_patches_g3.tfrecord.gz\" \\\n",
        "#   \"gs://csci5922-proj/unet/training_patches_g0.tfrecord.gz\" \\\n",
        "#   \"gs://csci5922-proj/unet/training_patches_g1.tfrecord.gz\" \\\n",
        "#   \"gs://csci5922-proj/unet/training_patches_g2.tfrecord.gz\" \\\n",
        "#   \"gs://csci5922-proj/unet/training_patches_g3.tfrecord.gz\" \\\n",
        "#   \"gs://csci5922-proj/unet/training_patches_g4.tfrecord.gz\" \\\n",
        "#   \"gs://csci5922-proj/unet/training_patches_g5.tfrecord.gz\" \\\n",
        "#   \"gs://csci5922-proj/unet/training_patches_g6.tfrecord.gz\" \\\n",
        "#   \"gs://csci5922-proj/unet/training_patches_g7.tfrecord.gz\" \\\n",
        "#   \"gs://csci5922-proj/unet/training_patches_g8.tfrecord.gz\" \\\n",
        "#   .\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWXrvBE4607G"
      },
      "source": [
        "# Training data\n",
        "\n",
        "Load the data exported from Earth Engine into a `tf.data.Dataset`.  The following are helper functions for that."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "WWZ0UXCVMyJP"
      },
      "outputs": [],
      "source": [
        "# from google.cloud import storage\n",
        "\n",
        "def parse_tfrecord(example_proto):\n",
        "  \"\"\"The parsing function.\n",
        "  Read a serialized example into the structure defined by FEATURES_DICT.\n",
        "  Args:\n",
        "    example_proto: a serialized Example.\n",
        "  Returns:\n",
        "    A dictionary of tensors, keyed by feature name.\n",
        "  \"\"\"\n",
        "  return tf.io.parse_single_example(example_proto, FEATURES_DICT)\n",
        "\n",
        "\n",
        "def to_tuple(inputs):\n",
        "  \"\"\"Function to convert a dictionary of tensors to a tuple of (inputs, outputs).\n",
        "  Turn the tensors returned by parse_tfrecord into a stack in HWC shape.\n",
        "  Args:\n",
        "    inputs: A dictionary of tensors, keyed by feature name.\n",
        "  Returns:\n",
        "    A tuple of (inputs, outputs).\n",
        "  \"\"\"\n",
        "  inputsList = [inputs.get(key) for key in FEATURES]\n",
        "  stacked = tf.stack(inputsList, axis=0)\n",
        "  # Convert from CHW to HWC\n",
        "  stacked = tf.transpose(stacked, [1, 2, 0])\n",
        "  return stacked[:,:,:len(BANDS)], stacked[:,:,len(BANDS):]\n",
        "\n",
        "\n",
        "def get_dataset(path, prefix, n_files):\n",
        "  \"\"\"Function to read, parse and format to tuple a set of input tfrecord files.\n",
        "  Get all the files matching the pattern, parse and convert to tuple.\n",
        "  Args:\n",
        "    pattern: A file pattern to match in a Cloud Storage bucket.\n",
        "  Returns:\n",
        "    A tf.data.Dataset\n",
        "  \"\"\"\n",
        "  # original code\n",
        "  # glob = tf.io.gfile.glob(pattern)\n",
        "  \n",
        "  # from the cloud\n",
        "  # https://cloud.google.com/appengine/docs/legacy/standard/python/googlecloudstorageclient/read-write-to-cloud-storage\n",
        "  # storage_client = storage.Client()\n",
        "  # bucket = storage_client.get_bucket(BUCKET)\n",
        "  # blobs = storage_client.list_blobs(BUCKET, prefix=pattern)\n",
        "  # glob = []\n",
        "  # for blob in blobs:\n",
        "  #   globs.append(blob.name)\n",
        "  # print(globs)\n",
        "  # # append bucket name to globs\n",
        "  # glob = ['gs://' + BUCKET + '/' + f for f in globs]\n",
        "\n",
        "  # read local tfrecord.gz files from unet-mini\n",
        "  glob = []\n",
        "  for i in range(0, n_files):\n",
        "    glob = path + prefix + '_g' + str(i) + '.tfrecord.gz'\n",
        "\n",
        "  # glob = [\n",
        "  #   '/Users/ilyonsg/Documents/courses/csci5922/proj/data/unet-mini/eval_patches_g0.tfrecord.gz',\n",
        "  #   '/Users/ilyonsg/Documents/courses/csci5922/proj/data/unet-mini/eval_patches_g1.tfrecord.gz'\n",
        "  # ]\n",
        "  dataset = tf.data.TFRecordDataset(glob, compression_type='GZIP')\n",
        "  dataset = dataset.map(parse_tfrecord, num_parallel_calls=5)\n",
        "  dataset = dataset.map(to_tuple, num_parallel_calls=5)\n",
        "  return dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xg1fa18336D2"
      },
      "source": [
        "Use the helpers to read in the training dataset.  Print the first record to check."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "rm0qRF0fAYcC"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/Users/ilyonsg/.config/gcloud/application_default_credentials.json\"\n",
        "\n",
        "def get_training_dataset():\n",
        "\t\"\"\"Get the preprocessed training dataset\n",
        "  Returns:\n",
        "    A tf.data.Dataset of training data.\n",
        "  \"\"\"\n",
        "\t# glob = 'gs://' + BUCKET + '/' + FOLDER + '/' + TRAINING_BASE + '*'\n",
        "\tdataset = get_dataset(DATA_PATH, TRAINING_BASE, 9)\n",
        "\tdataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
        "\treturn dataset\n",
        "\n",
        "training = get_training_dataset()\n",
        "\n",
        "# print(iter(training.take(1)).next())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-cQO5RL6vob"
      },
      "source": [
        "# Evaluation data\n",
        "\n",
        "Now do the same thing to get an evaluation dataset.  Note that unlike the training dataset, the evaluation dataset has a batch size of 1, is not repeated and is not shuffled.\n",
        "\n",
        "TODO: troubleshoot auth for cloud storage access, OR save things locally. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "ieKTCGiJ6xzo"
      },
      "outputs": [],
      "source": [
        "def get_eval_dataset():\n",
        "\t\"\"\"Get the preprocessed evaluation dataset\n",
        "  Returns:\n",
        "    A tf.data.Dataset of evaluation data.\n",
        "  \"\"\"\n",
        "\t# glob = 'gs://' + BUCKET + '/' + FOLDER + '/' + EVAL_BASE + '*'\n",
        "\t\n",
        "\tdataset = get_dataset(DATA_PATH, EVAL_BASE, 4)\n",
        "\tdataset = dataset.batch(1).repeat()\n",
        "\treturn dataset\n",
        "\n",
        "evaluation = get_eval_dataset()\n",
        "\n",
        "# print(iter(evaluation.take(1)).next())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JIE7Yl87lgU"
      },
      "source": [
        "# Model\n",
        "\n",
        "Here we use the Keras implementation of the U-Net model.  The U-Net model takes 256x256 pixel patches as input and outputs per-pixel class probability, label or a continuous output.  We can implement the model essentially unmodified, but will use mean squared error loss on the sigmoidal output since we are treating this as a regression problem, rather than a classification problem.  Since impervious surface fraction is constrained to [0,1], with many values close to zero or one, a saturating activation function is suitable here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "wsnnnz56yS3l"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "from keras import losses\n",
        "from keras import models\n",
        "from keras import metrics\n",
        "from keras import optimizers\n",
        "\n",
        "keras.backend.clear_session()\n",
        "\n",
        "def conv_block(input_tensor, num_filters):\n",
        "\tencoder = layers.Conv2D(num_filters, (3, 3), padding='same')(input_tensor)\n",
        "\tencoder = layers.BatchNormalization()(encoder)\n",
        "\tencoder = layers.Activation('relu')(encoder)\n",
        "\tencoder = layers.Conv2D(num_filters, (3, 3), padding='same')(encoder)\n",
        "\tencoder = layers.BatchNormalization()(encoder)\n",
        "\tencoder = layers.Activation('relu')(encoder)\n",
        "\treturn encoder\n",
        "\n",
        "def encoder_block(input_tensor, num_filters):\n",
        "\tencoder = conv_block(input_tensor, num_filters)\n",
        "\tencoder_pool = layers.MaxPooling2D((2, 2), strides=(2, 2))(encoder)\n",
        "\treturn encoder_pool, encoder\n",
        "\n",
        "def decoder_block(input_tensor, concat_tensor, num_filters):\n",
        "\tdecoder = layers.Conv2DTranspose(num_filters, (2, 2), strides=(2, 2), padding='same')(input_tensor)\n",
        "\tdecoder = layers.concatenate([concat_tensor, decoder], axis=-1)\n",
        "\tdecoder = layers.BatchNormalization()(decoder)\n",
        "\tdecoder = layers.Activation('relu')(decoder)\n",
        "\tdecoder = layers.Conv2D(num_filters, (3, 3), padding='same')(decoder)\n",
        "\tdecoder = layers.BatchNormalization()(decoder)\n",
        "\tdecoder = layers.Activation('relu')(decoder)\n",
        "\tdecoder = layers.Conv2D(num_filters, (3, 3), padding='same')(decoder)\n",
        "\tdecoder = layers.BatchNormalization()(decoder)\n",
        "\tdecoder = layers.Activation('relu')(decoder)\n",
        "\treturn decoder\n",
        "\n",
        "def get_model():\n",
        "\tinputs = layers.Input(shape=[None, None, len(BANDS)]) # 256\n",
        "\tencoder0_pool, encoder0 = encoder_block(inputs, 32) # 128\n",
        "\tencoder1_pool, encoder1 = encoder_block(encoder0_pool, 64) # 64\n",
        "\tencoder2_pool, encoder2 = encoder_block(encoder1_pool, 128) # 32\n",
        "\tencoder3_pool, encoder3 = encoder_block(encoder2_pool, 256) # 16\n",
        "\tencoder4_pool, encoder4 = encoder_block(encoder3_pool, 512) # 8\n",
        "\tcenter = conv_block(encoder4_pool, 1024) # center\n",
        "\tdecoder4 = decoder_block(center, encoder4, 512) # 16\n",
        "\tdecoder3 = decoder_block(decoder4, encoder3, 256) # 32\n",
        "\tdecoder2 = decoder_block(decoder3, encoder2, 128) # 64\n",
        "\tdecoder1 = decoder_block(decoder2, encoder1, 64) # 128\n",
        "\tdecoder0 = decoder_block(decoder1, encoder0, 32) # 256\n",
        "\toutputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(decoder0)\n",
        "\n",
        "\tmodel = models.Model(inputs=[inputs], outputs=[outputs])\n",
        "\n",
        "\tmodel.compile(\n",
        "\t\toptimizer=optimizers.get(OPTIMIZER),\n",
        "\t\tloss=losses.get(LOSS),\n",
        "\t\tmetrics=[metrics.get(metric) for metric in METRICS])\n",
        "\n",
        "\treturn model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uu_E7OTDBCoS"
      },
      "source": [
        "# Training the model\n",
        "\n",
        "You train a Keras model by calling `.fit()` on it.  Here we're going to train for 10 epochs, which is suitable for demonstration purposes.  For production use, you probably want to optimize this parameter, for example through [hyperparamter tuning](https://cloud.google.com/ml-engine/docs/tensorflow/using-hyperparameter-tuning)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "NzzaWxOhSxBy"
      },
      "outputs": [],
      "source": [
        "m = get_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Fit the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100/100 [==============================] - 1786s 18s/step - loss: 0.1672 - root_mean_squared_error: 0.4090 - val_loss: 0.1099 - val_root_mean_squared_error: 0.3315\n",
            "Epoch 2/5\n",
            "100/100 [==============================] - 1818s 18s/step - loss: 0.0961 - root_mean_squared_error: 0.3100 - val_loss: 0.0637 - val_root_mean_squared_error: 0.2523\n",
            "Epoch 3/5\n",
            "100/100 [==============================] - 1917s 19s/step - loss: 0.0813 - root_mean_squared_error: 0.2851 - val_loss: 0.0489 - val_root_mean_squared_error: 0.2211\n",
            "Epoch 4/5\n",
            " 64/100 [==================>...........] - ETA: 10:32 - loss: 0.0768 - root_mean_squared_error: 0.2770"
          ]
        }
      ],
      "source": [
        "# fit the model\n",
        "m.fit(\n",
        "    x=training,\n",
        "    epochs=5,\n",
        "    # epochs=EPOCHS,\n",
        "    steps_per_epoch=int(TRAIN_SIZE / BATCH_SIZE),\n",
        "    validation_data=evaluation,\n",
        "    validation_steps=EVAL_SIZE\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# save the model to a local file \n",
        "m.save('/Users/ilyonsg/Documents/courses/csci5922/proj/data/unet-viirs/unet_viirs5.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2XrwZHp66j4"
      },
      "source": [
        "Note that the notebook VM is sometimes not heavy-duty enough to get through a whole training job, especially if you have a large buffer size or a large number of epochs.  You can still use this notebook for training, but may need to set up an alternative VM ([learn more](https://research.google.com/colaboratory/local-runtimes.html)) for production use.  Alternatively, you can package your code for running large training jobs on Google's AI Platform [as described here](https://cloud.google.com/ml-engine/docs/tensorflow/trainer-considerations).  The following code loads a pre-trained model, which you can use for predictions right away."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "-RJpNfEUS1qp"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, None, None,  0           []                               \n",
            "                                 9)]                                                              \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, None, None,   2624        ['input_1[0][0]']                \n",
            "                                32)                                                               \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, None, None,   128        ['conv2d[0][0]']                 \n",
            " alization)                     32)                                                               \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, None, None,   0           ['batch_normalization[0][0]']    \n",
            "                                32)                                                               \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, None, None,   9248        ['activation[0][0]']             \n",
            "                                32)                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, None, None,   128        ['conv2d_1[0][0]']               \n",
            " rmalization)                   32)                                                               \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, None, None,   0           ['batch_normalization_1[0][0]']  \n",
            "                                32)                                                               \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, None, None,   0           ['activation_1[0][0]']           \n",
            "                                32)                                                               \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, None, None,   18496       ['max_pooling2d[0][0]']          \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, None, None,   256        ['conv2d_2[0][0]']               \n",
            " rmalization)                   64)                                                               \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, None, None,   0           ['batch_normalization_2[0][0]']  \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, None, None,   36928       ['activation_2[0][0]']           \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, None, None,   256        ['conv2d_3[0][0]']               \n",
            " rmalization)                   64)                                                               \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, None, None,   0           ['batch_normalization_3[0][0]']  \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, None, None,   0          ['activation_3[0][0]']           \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, None, None,   73856       ['max_pooling2d_1[0][0]']        \n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, None, None,   512        ['conv2d_4[0][0]']               \n",
            " rmalization)                   128)                                                              \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, None, None,   0           ['batch_normalization_4[0][0]']  \n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, None, None,   147584      ['activation_4[0][0]']           \n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, None, None,   512        ['conv2d_5[0][0]']               \n",
            " rmalization)                   128)                                                              \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, None, None,   0           ['batch_normalization_5[0][0]']  \n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, None, None,   0          ['activation_5[0][0]']           \n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, None, None,   295168      ['max_pooling2d_2[0][0]']        \n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, None, None,   1024       ['conv2d_6[0][0]']               \n",
            " rmalization)                   256)                                                              \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, None, None,   0           ['batch_normalization_6[0][0]']  \n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, None, None,   590080      ['activation_6[0][0]']           \n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, None, None,   1024       ['conv2d_7[0][0]']               \n",
            " rmalization)                   256)                                                              \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, None, None,   0           ['batch_normalization_7[0][0]']  \n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPooling2D)  (None, None, None,   0          ['activation_7[0][0]']           \n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, None, None,   1180160     ['max_pooling2d_3[0][0]']        \n",
            "                                512)                                                              \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, None, None,   2048       ['conv2d_8[0][0]']               \n",
            " rmalization)                   512)                                                              \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, None, None,   0           ['batch_normalization_8[0][0]']  \n",
            "                                512)                                                              \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, None, None,   2359808     ['activation_8[0][0]']           \n",
            "                                512)                                                              \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, None, None,   2048       ['conv2d_9[0][0]']               \n",
            " rmalization)                   512)                                                              \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, None, None,   0           ['batch_normalization_9[0][0]']  \n",
            "                                512)                                                              \n",
            "                                                                                                  \n",
            " max_pooling2d_4 (MaxPooling2D)  (None, None, None,   0          ['activation_9[0][0]']           \n",
            "                                512)                                                              \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, None, None,   4719616     ['max_pooling2d_4[0][0]']        \n",
            "                                1024)                                                             \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, None, None,   4096       ['conv2d_10[0][0]']              \n",
            " ormalization)                  1024)                                                             \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, None, None,   0           ['batch_normalization_10[0][0]'] \n",
            "                                1024)                                                             \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, None, None,   9438208     ['activation_10[0][0]']          \n",
            "                                1024)                                                             \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, None, None,   4096       ['conv2d_11[0][0]']              \n",
            " ormalization)                  1024)                                                             \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, None, None,   0           ['batch_normalization_11[0][0]'] \n",
            "                                1024)                                                             \n",
            "                                                                                                  \n",
            " conv2d_transpose (Conv2DTransp  (None, None, None,   2097664    ['activation_11[0][0]']          \n",
            " ose)                           512)                                                              \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, None, None,   0           ['activation_9[0][0]',           \n",
            "                                1024)                             'conv2d_transpose[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, None, None,   4096       ['concatenate[0][0]']            \n",
            " ormalization)                  1024)                                                             \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, None, None,   0           ['batch_normalization_12[0][0]'] \n",
            "                                1024)                                                             \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, None, None,   4719104     ['activation_12[0][0]']          \n",
            "                                512)                                                              \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, None, None,   2048       ['conv2d_12[0][0]']              \n",
            " ormalization)                  512)                                                              \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, None, None,   0           ['batch_normalization_13[0][0]'] \n",
            "                                512)                                                              \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, None, None,   2359808     ['activation_13[0][0]']          \n",
            "                                512)                                                              \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, None, None,   2048       ['conv2d_13[0][0]']              \n",
            " ormalization)                  512)                                                              \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, None, None,   0           ['batch_normalization_14[0][0]'] \n",
            "                                512)                                                              \n",
            "                                                                                                  \n",
            " conv2d_transpose_1 (Conv2DTran  (None, None, None,   524544     ['activation_14[0][0]']          \n",
            " spose)                         256)                                                              \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, None, None,   0           ['activation_7[0][0]',           \n",
            "                                512)                              'conv2d_transpose_1[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, None, None,   2048       ['concatenate_1[0][0]']          \n",
            " ormalization)                  512)                                                              \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, None, None,   0           ['batch_normalization_15[0][0]'] \n",
            "                                512)                                                              \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, None, None,   1179904     ['activation_15[0][0]']          \n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, None, None,   1024       ['conv2d_14[0][0]']              \n",
            " ormalization)                  256)                                                              \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, None, None,   0           ['batch_normalization_16[0][0]'] \n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, None, None,   590080      ['activation_16[0][0]']          \n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, None, None,   1024       ['conv2d_15[0][0]']              \n",
            " ormalization)                  256)                                                              \n",
            "                                                                                                  \n",
            " activation_17 (Activation)     (None, None, None,   0           ['batch_normalization_17[0][0]'] \n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " conv2d_transpose_2 (Conv2DTran  (None, None, None,   131200     ['activation_17[0][0]']          \n",
            " spose)                         128)                                                              \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, None, None,   0           ['activation_5[0][0]',           \n",
            "                                256)                              'conv2d_transpose_2[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, None, None,   1024       ['concatenate_2[0][0]']          \n",
            " ormalization)                  256)                                                              \n",
            "                                                                                                  \n",
            " activation_18 (Activation)     (None, None, None,   0           ['batch_normalization_18[0][0]'] \n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, None, None,   295040      ['activation_18[0][0]']          \n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, None, None,   512        ['conv2d_16[0][0]']              \n",
            " ormalization)                  128)                                                              \n",
            "                                                                                                  \n",
            " activation_19 (Activation)     (None, None, None,   0           ['batch_normalization_19[0][0]'] \n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, None, None,   147584      ['activation_19[0][0]']          \n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, None, None,   512        ['conv2d_17[0][0]']              \n",
            " ormalization)                  128)                                                              \n",
            "                                                                                                  \n",
            " activation_20 (Activation)     (None, None, None,   0           ['batch_normalization_20[0][0]'] \n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " conv2d_transpose_3 (Conv2DTran  (None, None, None,   32832      ['activation_20[0][0]']          \n",
            " spose)                         64)                                                               \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, None, None,   0           ['activation_3[0][0]',           \n",
            "                                128)                              'conv2d_transpose_3[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, None, None,   512        ['concatenate_3[0][0]']          \n",
            " ormalization)                  128)                                                              \n",
            "                                                                                                  \n",
            " activation_21 (Activation)     (None, None, None,   0           ['batch_normalization_21[0][0]'] \n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, None, None,   73792       ['activation_21[0][0]']          \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, None, None,   256        ['conv2d_18[0][0]']              \n",
            " ormalization)                  64)                                                               \n",
            "                                                                                                  \n",
            " activation_22 (Activation)     (None, None, None,   0           ['batch_normalization_22[0][0]'] \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, None, None,   36928       ['activation_22[0][0]']          \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, None, None,   256        ['conv2d_19[0][0]']              \n",
            " ormalization)                  64)                                                               \n",
            "                                                                                                  \n",
            " activation_23 (Activation)     (None, None, None,   0           ['batch_normalization_23[0][0]'] \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " conv2d_transpose_4 (Conv2DTran  (None, None, None,   8224       ['activation_23[0][0]']          \n",
            " spose)                         32)                                                               \n",
            "                                                                                                  \n",
            " concatenate_4 (Concatenate)    (None, None, None,   0           ['activation_1[0][0]',           \n",
            "                                64)                               'conv2d_transpose_4[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, None, None,   256        ['concatenate_4[0][0]']          \n",
            " ormalization)                  64)                                                               \n",
            "                                                                                                  \n",
            " activation_24 (Activation)     (None, None, None,   0           ['batch_normalization_24[0][0]'] \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, None, None,   18464       ['activation_24[0][0]']          \n",
            "                                32)                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, None, None,   128        ['conv2d_20[0][0]']              \n",
            " ormalization)                  32)                                                               \n",
            "                                                                                                  \n",
            " activation_25 (Activation)     (None, None, None,   0           ['batch_normalization_25[0][0]'] \n",
            "                                32)                                                               \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, None, None,   9248        ['activation_25[0][0]']          \n",
            "                                32)                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, None, None,   128        ['conv2d_21[0][0]']              \n",
            " ormalization)                  32)                                                               \n",
            "                                                                                                  \n",
            " activation_26 (Activation)     (None, None, None,   0           ['batch_normalization_26[0][0]'] \n",
            "                                32)                                                               \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, None, None,   33          ['activation_26[0][0]']          \n",
            "                                1)                                                                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 31,128,225\n",
            "Trainable params: 31,112,225\n",
            "Non-trainable params: 16,000\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# import os\n",
        "# os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/Users/ilyonsg/.config/gcloud/application_default_credentials.json\"\n",
        "# Load a trained model. 50 epochs. 25 hours. Final RMSE ~0.08.\n",
        "\n",
        "\n",
        "# MODEL_DIR = 'gs://ee-docs-demos/fcnn-demo/trainer/model'\n",
        "# m = tf.keras.models.load_model(MODEL_DIR)\n",
        "\n",
        "m.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1ySNup0xCqN"
      },
      "source": [
        "# Prediction\n",
        "\n",
        "The prediction pipeline is:\n",
        "\n",
        "1.  Export imagery on which to do predictions from Earth Engine in TFRecord format to a Cloud Storage bucket.\n",
        "2.  Use the trained model to make the predictions.\n",
        "3.  Write the predictions to a TFRecord file in a Cloud Storage.\n",
        "4.  Upload the predictions TFRecord file to Earth Engine.\n",
        "\n",
        "The following functions handle this process.  It's useful to separate the export from the predictions so that you can experiment with different models without running the export every time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Export Sample Imagery for Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "M3WDAa-RUpXP"
      },
      "outputs": [],
      "source": [
        "def doExport(out_image_base, kernel_buffer, region):\n",
        "  \"\"\"Run the image export task.  Block until complete.\n",
        "  \"\"\"\n",
        "  task = ee.batch.Export.image.toCloudStorage(\n",
        "    image = image.select(BANDS),\n",
        "    description = out_image_base,\n",
        "    bucket = BUCKET,\n",
        "    fileNamePrefix = FOLDER + '/' + out_image_base,\n",
        "    region = region.getInfo()['coordinates'],\n",
        "    scale = 30,\n",
        "    fileFormat = 'TFRecord',\n",
        "    maxPixels = 1e10,\n",
        "    formatOptions = {\n",
        "      'patchDimensions': KERNEL_SHAPE,\n",
        "      'kernelSize': kernel_buffer,\n",
        "      'compressed': True,\n",
        "      'maxFileSize': 104857600\n",
        "    }\n",
        "  )\n",
        "  task.start()\n",
        "\n",
        "  # Block until the task completes.\n",
        "  print('Running image export to Cloud Storage...')\n",
        "  import time\n",
        "  while task.active():\n",
        "    time.sleep(30)\n",
        "\n",
        "  # Error condition\n",
        "  if task.status()['state'] != 'COMPLETED':\n",
        "    print('Error with image export.')\n",
        "  else:\n",
        "    print('Image export completed.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define Code for Running Model on Prediction Data\n",
        "Modified to run on local data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "zb_9_FflygVw"
      },
      "outputs": [],
      "source": [
        "def doPrediction(out_image_base, kernel_buffer):\n",
        "  \"\"\"Perform inference on exported imagery, upload to Earth Engine.\n",
        "  \"\"\"\n",
        "\n",
        "  print('Looking for TFRecord files...')\n",
        "\n",
        "  # # Get a list of all the files in the output bucket.\n",
        "  # filesList = !gsutil ls 'gs://'{BUCKET}'/'{FOLDER}\n",
        "  # Get a list of all local files in /data/unet-mini\n",
        "  filesList = !ls '/Users/ilyonsg/Documents/courses/csci5922/proj/data/unet-mini'\n",
        "\n",
        "  # Get only the files generated by the image export.\n",
        "  exportFilesList = [s for s in filesList if out_image_base in s]\n",
        "\n",
        "  # Get the list of image files and the JSON mixer file.\n",
        "  imageFilesList = []\n",
        "  jsonFile = None\n",
        "  for f in exportFilesList:\n",
        "    if f.endswith('.tfrecord.gz'):\n",
        "      imageFilesList.append(f)\n",
        "    elif f.endswith('.json'):\n",
        "      jsonFile = f\n",
        "\n",
        "  # Make sure the files are in the right order.\n",
        "  imageFilesList.sort()\n",
        "\n",
        "  from pprint import pprint\n",
        "  pprint(imageFilesList)\n",
        "  print(jsonFile)\n",
        "\n",
        "  import json\n",
        "  # Load the contents of the mixer file to a JSON object.\n",
        "  # jsonText = !gsutil cat {jsonFile}  \n",
        "  jsonText = !cat '/Users/ilyonsg/Documents/courses/csci5922/proj/data/unet-mini/FCNN_demo_beijing_384_mixer.json'\n",
        "  print(jsonText)\n",
        "  # Get a single string w/ newlines from the IPython.utils.text.SList\n",
        "  mixer = json.loads(jsonText.nlstr)\n",
        "  pprint(mixer)\n",
        "  patches = mixer['totalPatches']\n",
        "\n",
        "\n",
        "\n",
        "  buffered_shape = [\n",
        "      KERNEL_SHAPE[0] + kernel_buffer[0],\n",
        "      KERNEL_SHAPE[1] + kernel_buffer[1]]\n",
        "\n",
        "  imageColumns = [\n",
        "    tf.io.FixedLenFeature(shape=buffered_shape, dtype=tf.float32)\n",
        "      for k in BANDS\n",
        "  ]\n",
        "\n",
        "  imageFeaturesDict = dict(zip(BANDS, imageColumns))\n",
        "\n",
        "  def parse_image(example_proto):\n",
        "    return tf.io.parse_single_example(example_proto, imageFeaturesDict)\n",
        "\n",
        "  def toTupleImage(inputs):\n",
        "    inputsList = [inputs.get(key) for key in BANDS]\n",
        "    stacked = tf.stack(inputsList, axis=0)\n",
        "    stacked = tf.transpose(stacked, [1, 2, 0])\n",
        "    return stacked\n",
        "\n",
        "  # append absolute path to imageFilesList\n",
        "  imageFilesList = [DATA_PATH + f for f in imageFilesList]\n",
        "  print(imageFilesList)\n",
        "  \n",
        "  # Create a dataset from the TFRecord file(s) in Cloud Storage.\n",
        "  imageDataset = tf.data.TFRecordDataset(imageFilesList, compression_type='GZIP')\n",
        "  imageDataset = imageDataset.map(parse_image, num_parallel_calls=5)\n",
        "  imageDataset = imageDataset.map(toTupleImage).batch(1)\n",
        "\n",
        "  # print(imageDataset)\n",
        "\n",
        "  # Perform inference.\n",
        "  print('Running predictions...')\n",
        "  predictions = m.predict(imageDataset, steps=patches, verbose=1)\n",
        "  # print(predictions[0])\n",
        "  return predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def writePredictions(predictions, out_image_base, kernel_buffer):\n",
        "  print('Writing predictions...')\n",
        "  out_image_file = 'gs://' + BUCKET + '/' + FOLDER + '/' + out_image_base + '.TFRecord'\n",
        "  # out_image_file = '/Users/ilyonsg/Documents/courses/csci5922/proj/data/unet-mini/' + out_image_base + '.TFRecord'\n",
        "\n",
        "  # Get set up for prediction.\n",
        "  x_buffer = int(kernel_buffer[0] / 2)\n",
        "  y_buffer = int(kernel_buffer[1] / 2)\n",
        "  \n",
        "  \n",
        "  writer = tf.io.TFRecordWriter(out_image_file)\n",
        "  patches = 0\n",
        "  for predictionPatch in predictions:\n",
        "    print('Writing patch ' + str(patches) + '...')\n",
        "    predictionPatch = predictionPatch[\n",
        "        x_buffer:x_buffer+KERNEL_SIZE, y_buffer:y_buffer+KERNEL_SIZE]\n",
        "\n",
        "    # Create an example.\n",
        "    example = tf.train.Example(\n",
        "      features=tf.train.Features(\n",
        "        feature={\n",
        "          'impervious': tf.train.Feature(\n",
        "            float_list=tf.train.FloatList(\n",
        "              value=predictionPatch.flatten()\n",
        "            )\n",
        "          )\n",
        "        }\n",
        "      )\n",
        "    )\n",
        "    # Write the example.\n",
        "    writer.write(example.SerializeToString())\n",
        "    patches += 1\n",
        "\n",
        "  print('Done for looping.')\n",
        "  writer.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "def uploadPredictionsToEE(out_image_base, user_folder):\n",
        "  # Start the upload.\n",
        "  print('Uploading to Google Earth Egnine...')\n",
        "  \n",
        "  # define file paths\n",
        "  out_image_file = 'gs://' + BUCKET + '/' + FOLDER + '/' + out_image_base + '.TFRecord'\n",
        "  out_image_asset = user_folder + '/' + out_image_base\n",
        "  jsonFile = 'gs://' + BUCKET + '/' + FOLDER + '/' + 'FCNN_demo_beijing_384_mixer.json'\n",
        "  # jsonFile = '/Users/ilyonsg/Documents/courses/csci5922/proj/data/unet-mini/FCNN_demo_beijing_384_mixer.json'\n",
        "  \n",
        "  print('out_image_asset: ', out_image_asset)\n",
        "  print('out_image_file: ', out_image_file)\n",
        "  print('jsonFile: ', jsonFile)\n",
        "  \n",
        "  # upload file to google earth engine from gcs\n",
        "  # !earthengine upload image --asset_id={out_image_asset} {out_image_file} {jsonFile}\n",
        "  !earthengine upload image --asset_id={out_image_asset} {out_image_file} {jsonFile}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZqlymOehnQO"
      },
      "source": [
        "Now there's all the code needed to run the prediction pipeline, all that remains is to specify the output region in which to do the prediction, the names of the output files, where to put them, and the shape of the outputs.  In terms of the shape, the model is trained on 256x256 patches, but can work (in theory) on any patch that's big enough with even dimensions ([reference](https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Long_Fully_Convolutional_Networks_2015_CVPR_paper.pdf)).  Because of tile boundary artifacts, give the model slightly larger patches for prediction, then clip out the middle 256x256 patch.  This is controlled with a kernel buffer, half the size of which will extend beyond the kernel buffer.  For example, specifying a 128x128 kernel will append 64 pixels on each side of the patch, to ensure that the pixels in the output are taken from inputs completely covered by the kernel."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Specify Region and Outputs for Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "FPANwc7B1-TS"
      },
      "outputs": [],
      "source": [
        "# Output assets folder: YOUR FOLDER\n",
        "user_folder = 'projects/master-thesis-ilg/assets' # INSERT YOUR FOLDER HERE.\n",
        "\n",
        "# Base file name to use for TFRecord files and assets.\n",
        "bj_image_base = 'FCNN_demo_beijing_384_'\n",
        "# Half this will extend on the sides of each patch.\n",
        "bj_kernel_buffer = [128, 128]\n",
        "# Beijing\n",
        "bj_region = ee.Geometry.Polygon(\n",
        "        [[[115.9662455210937, 40.121362012835235],\n",
        "          [115.9662455210937, 39.64293313749715],\n",
        "          [117.01818643906245, 39.64293313749715],\n",
        "          [117.01818643906245, 40.121362012835235]]], None, False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "lLNEOLkXWvSi"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running image export to Cloud Storage...\n",
            "Image export completed.\n"
          ]
        }
      ],
      "source": [
        "# Run the export.\n",
        "doExport(bj_image_base, bj_kernel_buffer, bj_region)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "If you experience problems with multiprocessing on MacOS, they might be related to https://bugs.python.org/issue33725. You can disable multiprocessing by editing your .boto config or by adding the following flag to your command: `-o \"GSUtil:parallel_process_count=1\"`. Note that multithreading is still available even if you disable multiprocessing.\n",
            "\n",
            "Copying gs://csci5922-proj/unet/FCNN_demo_beijing_384_00000.tfrecord.gz...\n",
            "Copying gs://csci5922-proj/unet/FCNN_demo_beijing_384_00001.tfrecord.gz...      \n",
            "Copying gs://csci5922-proj/unet/FCNN_demo_beijing_384_00002.tfrecord.gz...      \n",
            "Copying gs://csci5922-proj/unet/FCNN_demo_beijing_384_00003.tfrecord.gz...      \n",
            "Copying gs://csci5922-proj/unet/FCNN_demo_beijing_384_00004.tfrecord.gz...      \n",
            "Copying gs://csci5922-proj/unet/FCNN_demo_beijing_384_mixer.json...             \n",
            "| [6/6 files][187.0 MiB/187.0 MiB] 100% Done  11.8 MiB/s ETA 00:00:00           \n",
            "Operation completed over 6 objects/187.0 MiB.                                    \n"
          ]
        }
      ],
      "source": [
        "# copy the file from cloud storage to local\n",
        "!gsutil -m cp \\\n",
        "  \"gs://csci5922-proj/unet/FCNN_demo_beijing_384_00000.tfrecord.gz\" \\\n",
        "  \"gs://csci5922-proj/unet/FCNN_demo_beijing_384_00001.tfrecord.gz\" \\\n",
        "  \"gs://csci5922-proj/unet/FCNN_demo_beijing_384_00002.tfrecord.gz\" \\\n",
        "  \"gs://csci5922-proj/unet/FCNN_demo_beijing_384_00003.tfrecord.gz\" \\\n",
        "  \"gs://csci5922-proj/unet/FCNN_demo_beijing_384_00004.tfrecord.gz\" \\\n",
        "  \"gs://csci5922-proj/unet/FCNN_demo_beijing_384_mixer.json\" \\\n",
        "  \"/Users/ilyonsg/Documents/courses/csci5922/proj/data/unet-viirs\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "KxACnxKFrQ_J"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking for TFRecord files...\n",
            "['FCNN_demo_beijing_384_00000.tfrecord.gz',\n",
            " 'FCNN_demo_beijing_384_00001.tfrecord.gz',\n",
            " 'FCNN_demo_beijing_384_00002.tfrecord.gz',\n",
            " 'FCNN_demo_beijing_384_00003.tfrecord.gz',\n",
            " 'FCNN_demo_beijing_384_00004.tfrecord.gz']\n",
            "FCNN_demo_beijing_384_mixer.json\n",
            "['{', '  \"projection\": {', '    \"crs\": \"EPSG:4326\",', '    \"affine\": {', '      \"doubleMatrix\": [2.6949458523585647E-4, 0.0, 115.9662149728414, 0.0, -2.6949458523585647E-4, 40.122623344499544]', '    }', '  },', '  \"patchDimensions\": [256, 256],', '  \"patchesPerRow\": 15,', '  \"totalPatches\": 90', '}']\n",
            "{'patchDimensions': [256, 256],\n",
            " 'patchesPerRow': 15,\n",
            " 'projection': {'affine': {'doubleMatrix': [0.00026949458523585647,\n",
            "                                            0.0,\n",
            "                                            115.9662149728414,\n",
            "                                            0.0,\n",
            "                                            -0.00026949458523585647,\n",
            "                                            40.122623344499544]},\n",
            "                'crs': 'EPSG:4326'},\n",
            " 'totalPatches': 90}\n",
            "['/Users/ilyonsg/Documents/courses/csci5922/proj/data/unet-viirs/FCNN_demo_beijing_384_00000.tfrecord.gz', '/Users/ilyonsg/Documents/courses/csci5922/proj/data/unet-viirs/FCNN_demo_beijing_384_00001.tfrecord.gz', '/Users/ilyonsg/Documents/courses/csci5922/proj/data/unet-viirs/FCNN_demo_beijing_384_00002.tfrecord.gz', '/Users/ilyonsg/Documents/courses/csci5922/proj/data/unet-viirs/FCNN_demo_beijing_384_00003.tfrecord.gz', '/Users/ilyonsg/Documents/courses/csci5922/proj/data/unet-viirs/FCNN_demo_beijing_384_00004.tfrecord.gz']\n",
            "Running predictions...\n",
            "90/90 [==============================] - 53s 579ms/step\n"
          ]
        }
      ],
      "source": [
        "# Run the prediction.\n",
        "predictions = doPrediction(bj_image_base, bj_kernel_buffer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing predictions...\n",
            "Writing patch 0...\n",
            "Writing patch 1...\n",
            "Writing patch 2...\n",
            "Writing patch 3...\n",
            "Writing patch 4...\n",
            "Writing patch 5...\n",
            "Writing patch 6...\n",
            "Writing patch 7...\n",
            "Writing patch 8...\n",
            "Writing patch 9...\n",
            "Writing patch 10...\n",
            "Writing patch 11...\n",
            "Writing patch 12...\n",
            "Writing patch 13...\n",
            "Writing patch 14...\n",
            "Writing patch 15...\n",
            "Writing patch 16...\n",
            "Writing patch 17...\n",
            "Writing patch 18...\n",
            "Writing patch 19...\n",
            "Writing patch 20...\n",
            "Writing patch 21...\n",
            "Writing patch 22...\n",
            "Writing patch 23...\n",
            "Writing patch 24...\n",
            "Writing patch 25...\n",
            "Writing patch 26...\n",
            "Writing patch 27...\n",
            "Writing patch 28...\n",
            "Writing patch 29...\n",
            "Writing patch 30...\n",
            "Writing patch 31...\n",
            "Writing patch 32...\n",
            "Writing patch 33...\n",
            "Writing patch 34...\n",
            "Writing patch 35...\n",
            "Writing patch 36...\n",
            "Writing patch 37...\n",
            "Writing patch 38...\n",
            "Writing patch 39...\n",
            "Writing patch 40...\n",
            "Writing patch 41...\n",
            "Writing patch 42...\n",
            "Writing patch 43...\n",
            "Writing patch 44...\n",
            "Writing patch 45...\n",
            "Writing patch 46...\n",
            "Writing patch 47...\n",
            "Writing patch 48...\n",
            "Writing patch 49...\n",
            "Writing patch 50...\n",
            "Writing patch 51...\n",
            "Writing patch 52...\n",
            "Writing patch 53...\n",
            "Writing patch 54...\n",
            "Writing patch 55...\n",
            "Writing patch 56...\n",
            "Writing patch 57...\n",
            "Writing patch 58...\n",
            "Writing patch 59...\n",
            "Writing patch 60...\n",
            "Writing patch 61...\n",
            "Writing patch 62...\n",
            "Writing patch 63...\n",
            "Writing patch 64...\n",
            "Writing patch 65...\n",
            "Writing patch 66...\n",
            "Writing patch 67...\n",
            "Writing patch 68...\n",
            "Writing patch 69...\n",
            "Writing patch 70...\n",
            "Writing patch 71...\n",
            "Writing patch 72...\n",
            "Writing patch 73...\n",
            "Writing patch 74...\n",
            "Writing patch 75...\n",
            "Writing patch 76...\n",
            "Writing patch 77...\n",
            "Writing patch 78...\n",
            "Writing patch 79...\n",
            "Writing patch 80...\n",
            "Writing patch 81...\n",
            "Writing patch 82...\n",
            "Writing patch 83...\n",
            "Writing patch 84...\n",
            "Writing patch 85...\n",
            "Writing patch 86...\n",
            "Writing patch 87...\n",
            "Writing patch 88...\n",
            "Writing patch 89...\n",
            "Done for looping.\n"
          ]
        }
      ],
      "source": [
        "# Write the predictions.\n",
        "writePredictions(predictions, bj_image_base, bj_kernel_buffer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Uploading to Google Earth Egnine...\n",
            "out_image_asset:  projects/master-thesis-ilg/assets/FCNN_demo_beijing_384_\n",
            "out_image_file:  gs://csci5922-proj/unet-viirs/FCNN_demo_beijing_384_.TFRecord\n",
            "jsonFile:  gs://csci5922-proj/unet-viirs/FCNN_demo_beijing_384_mixer.json\n",
            "/Users/ilyonsg/miniconda3/envs/tfgee/lib/python3.9/site-packages/scipy/__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.2\n",
            "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
            "Started upload task with ID: TYUDEGQNWT4IJZ6M4PJTD43Y\n"
          ]
        }
      ],
      "source": [
        "# upload to earth engine\n",
        "# change the name of the last prediction on gee before running this or the task will error\n",
        "uploadPredictionsToEE(bj_image_base, user_folder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uj_G9OZ1xH6K"
      },
      "source": [
        "# Display the output\n",
        "\n",
        "One the data has been exported, the model has made predictions and the predictions have been written to a file, and the image imported to Earth Engine, it's possible to display the resultant Earth Engine asset.  Here, display the impervious area predictions over Beijing, China."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "Jgco6HJ4R5p2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><span style=\"color:#565656\">Make this Notebook Trusted to load map: File -> Trust Notebook</span><iframe srcdoc=\"&lt;!DOCTYPE html&gt;\n",
              "&lt;html&gt;\n",
              "&lt;head&gt;\n",
              "    \n",
              "    &lt;meta http-equiv=&quot;content-type&quot; content=&quot;text/html; charset=UTF-8&quot; /&gt;\n",
              "    \n",
              "        &lt;script&gt;\n",
              "            L_NO_TOUCH = false;\n",
              "            L_DISABLE_3D = false;\n",
              "        &lt;/script&gt;\n",
              "    \n",
              "    &lt;style&gt;html, body {width: 100%;height: 100%;margin: 0;padding: 0;}&lt;/style&gt;\n",
              "    &lt;style&gt;#map {position:absolute;top:0;bottom:0;right:0;left:0;}&lt;/style&gt;\n",
              "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;script src=&quot;https://code.jquery.com/jquery-3.7.1.min.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/js/bootstrap.bundle.min.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/css/bootstrap.min.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap.min.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.2.0/css/all.min.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/gh/python-visualization/folium/folium/templates/leaflet.awesome.rotate.min.css&quot;/&gt;\n",
              "    \n",
              "            &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width,\n",
              "                initial-scale=1.0, maximum-scale=1.0, user-scalable=no&quot; /&gt;\n",
              "            &lt;style&gt;\n",
              "                #map_4825b55d2737c89e1c59d2aedf055f99 {\n",
              "                    position: relative;\n",
              "                    width: 100.0%;\n",
              "                    height: 100.0%;\n",
              "                    left: 0.0%;\n",
              "                    top: 0.0%;\n",
              "                }\n",
              "                .leaflet-container { font-size: 1rem; }\n",
              "            &lt;/style&gt;\n",
              "        \n",
              "&lt;/head&gt;\n",
              "&lt;body&gt;\n",
              "    \n",
              "    \n",
              "            &lt;div class=&quot;folium-map&quot; id=&quot;map_4825b55d2737c89e1c59d2aedf055f99&quot; &gt;&lt;/div&gt;\n",
              "        \n",
              "&lt;/body&gt;\n",
              "&lt;script&gt;\n",
              "    \n",
              "    \n",
              "            var map_4825b55d2737c89e1c59d2aedf055f99 = L.map(\n",
              "                &quot;map_4825b55d2737c89e1c59d2aedf055f99&quot;,\n",
              "                {\n",
              "                    center: [39.898, 116.5097],\n",
              "                    crs: L.CRS.EPSG3857,\n",
              "                    zoom: 10,\n",
              "                    zoomControl: true,\n",
              "                    preferCanvas: false,\n",
              "                }\n",
              "            );\n",
              "\n",
              "            \n",
              "\n",
              "        \n",
              "    \n",
              "            var tile_layer_f00bd7a223581a6af9fb9cb71ba9853f = L.tileLayer(\n",
              "                &quot;https://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png&quot;,\n",
              "                {&quot;attribution&quot;: &quot;Data by \\u0026copy; \\u003ca target=\\&quot;_blank\\&quot; href=\\&quot;http://openstreetmap.org\\&quot;\\u003eOpenStreetMap\\u003c/a\\u003e, under \\u003ca target=\\&quot;_blank\\&quot; href=\\&quot;http://www.openstreetmap.org/copyright\\&quot;\\u003eODbL\\u003c/a\\u003e.&quot;, &quot;detectRetina&quot;: false, &quot;maxNativeZoom&quot;: 18, &quot;maxZoom&quot;: 18, &quot;minZoom&quot;: 0, &quot;noWrap&quot;: false, &quot;opacity&quot;: 1, &quot;subdomains&quot;: &quot;abc&quot;, &quot;tms&quot;: false}\n",
              "            );\n",
              "        \n",
              "    \n",
              "                tile_layer_f00bd7a223581a6af9fb9cb71ba9853f.addTo(map_4825b55d2737c89e1c59d2aedf055f99);\n",
              "    \n",
              "            var tile_layer_345c4207093e261ed6e92592af688b90 = L.tileLayer(\n",
              "                &quot;https://earthengine.googleapis.com/v1/projects/earthengine-legacy/maps/2a243153942ca15dfd1be7c527d3b0dc-04f5710b3098c0289a35bf95ba8a19e2/tiles/{z}/{x}/{y}&quot;,\n",
              "                {&quot;attribution&quot;: &quot;Map Data \\u0026copy; \\u003ca href=\\&quot;https://earthengine.google.com/\\&quot;\\u003eGoogle Earth Engine\\u003c/a\\u003e&quot;, &quot;detectRetina&quot;: false, &quot;maxNativeZoom&quot;: 18, &quot;maxZoom&quot;: 18, &quot;minZoom&quot;: 0, &quot;noWrap&quot;: false, &quot;opacity&quot;: 1, &quot;subdomains&quot;: &quot;abc&quot;, &quot;tms&quot;: false}\n",
              "            );\n",
              "        \n",
              "    \n",
              "                tile_layer_345c4207093e261ed6e92592af688b90.addTo(map_4825b55d2737c89e1c59d2aedf055f99);\n",
              "    \n",
              "            var layer_control_f21a4a4261283bb34d7d8af71070d3eb_layers = {\n",
              "                base_layers : {\n",
              "                    &quot;openstreetmap&quot; : tile_layer_f00bd7a223581a6af9fb9cb71ba9853f,\n",
              "                },\n",
              "                overlays :  {\n",
              "                    &quot;predicted impervious&quot; : tile_layer_345c4207093e261ed6e92592af688b90,\n",
              "                },\n",
              "            };\n",
              "            let layer_control_f21a4a4261283bb34d7d8af71070d3eb = L.control.layers(\n",
              "                layer_control_f21a4a4261283bb34d7d8af71070d3eb_layers.base_layers,\n",
              "                layer_control_f21a4a4261283bb34d7d8af71070d3eb_layers.overlays,\n",
              "                {&quot;autoZIndex&quot;: true, &quot;collapsed&quot;: true, &quot;position&quot;: &quot;topright&quot;}\n",
              "            ).addTo(map_4825b55d2737c89e1c59d2aedf055f99);\n",
              "\n",
              "        \n",
              "&lt;/script&gt;\n",
              "&lt;/html&gt;\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
            ],
            "text/plain": [
              "<folium.folium.Map at 0x16adb1c40>"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "out_image = ee.Image(user_folder + '/' + bj_image_base)\n",
        "mapid = out_image.getMapId({'min': 0, 'max': 1})\n",
        "map = folium.Map(location=[39.898, 116.5097])\n",
        "folium.TileLayer(\n",
        "    tiles=mapid['tile_fetcher'].url_format,\n",
        "    attr='Map Data &copy; <a href=\"https://earthengine.google.com/\">Google Earth Engine</a>',\n",
        "    overlay=True,\n",
        "    name='predicted impervious',\n",
        "  ).add_to(map)\n",
        "map.add_child(folium.LayerControl())\n",
        "map"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
